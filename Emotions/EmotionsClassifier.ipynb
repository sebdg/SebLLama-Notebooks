{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install  pandas transformers datasets matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
      "       'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
      "       'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
      "       'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
      "       'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from load_data import load_data, load_tokenizer\n",
    "tokenizer = load_tokenizer()\n",
    "train = pd.read_parquet(\"go_emotions_train.parquet\")\n",
    "test = pd.read_parquet(\"go_emotions_test.parquet\")\n",
    "\n",
    "emotions = train.columns[1:29]\n",
    "print(emotions)\n",
    "\n",
    "\n",
    "max_sequence_length = 200\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(tokenizer, max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_emotions_to_string(array_of_labels):\n",
    "    \"\"\"Decode the emotions from the row to a list of strings.\"\"\"\n",
    "    # active labels are 1, inactive are 0\n",
    "    return [emotion for i, emotion in enumerate(emotions) if array_of_labels[i] == 1]\n",
    "\n",
    "\n",
    "def decode_emotions_to_index(row):\n",
    "    \"\"\"Decode the emotions from the row to a list of indices.\"\"\"\n",
    "    return [i for i, emotion in enumerate(emotions) if row[emotion] == 1]\n",
    "\n",
    "def decode_logits(row, k=3, alphabetic_sort=False):\n",
    "    \"\"\"Decode the logits from the row to a list of strings.\"\"\"\n",
    "    top = np.argsort(row)[-k:]\n",
    "    if alphabetic_sort:\n",
    "        top.sort()\n",
    "    return [emotions[i] for i in top]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Text length distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "train[\"length_text\"] = train[\"text\"].apply(len)\n",
    "train['length_text'].plot(kind='hist', title='Text length distribution')\n",
    "\n",
    "test[\"length_text\"] = test[\"text\"].apply(len)\n",
    "test['length_text'].plot(kind='hist', title='Text length distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with text length > max_sequence_length   \n",
    "train = train[train[\"length_text\"] <= max_sequence_length]\n",
    "test = test[test[\"length_text\"] <= max_sequence_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Text length distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "train[\"length_text\"] = train[\"text\"].apply(len)\n",
    "train['length_text'].plot(kind='hist', title='Text length distribution')\n",
    "\n",
    "test[\"length_text\"] = test[\"text\"].apply(len)\n",
    "test['length_text'].plot(kind='hist', title='Text length distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>neutral_only</th>\n",
       "      <th>neutral_and_other</th>\n",
       "      <th>neutral_above_1</th>\n",
       "      <th>length_text</th>\n",
       "      <th>positive_sum</th>\n",
       "      <th>negative_sum</th>\n",
       "      <th>neutral_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>As long as the minority aren't \"minorities\" I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34642</th>\n",
       "      <td>Same, I still need to sleep to go to work tomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>Bide your time, keep your eyes open, and build...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>Clock the flair but What are the judges on? I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47759</th>\n",
       "      <td>Who's the top three craft brewers in the area??</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>At least I can rest easy, knowing [NAME] isn't...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39881</th>\n",
       "      <td>That's the same thing 8 year olds use to try a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45572</th>\n",
       "      <td>Watching Shark Tank makes me wonder how so man...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>I guess. I respect the boots on the ground cop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>Because we feed the shitty ones so there is no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51515 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  admiration  \\\n",
       "4095   As long as the minority aren't \"minorities\" I ...           0   \n",
       "34642  Same, I still need to sleep to go to work tomo...           0   \n",
       "5142   Bide your time, keep your eyes open, and build...           0   \n",
       "6323   Clock the flair but What are the judges on? I ...           0   \n",
       "47759    Who's the top three craft brewers in the area??           0   \n",
       "...                                                  ...         ...   \n",
       "4205   At least I can rest easy, knowing [NAME] isn't...           0   \n",
       "39881  That's the same thing 8 year olds use to try a...           0   \n",
       "45572  Watching Shark Tank makes me wonder how so man...           0   \n",
       "15864  I guess. I respect the boots on the ground cop...           1   \n",
       "4910   Because we feed the shitty ones so there is no...           0   \n",
       "\n",
       "       amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
       "4095           0      0          0         0       0          0          0   \n",
       "34642          0      0          0         1       0          0          0   \n",
       "5142           0      0          0         0       1          0          0   \n",
       "6323           0      0          0         0       0          0          1   \n",
       "47759          0      0          0         0       0          0          1   \n",
       "...          ...    ...        ...       ...     ...        ...        ...   \n",
       "4205           0      0          0         0       0          0          0   \n",
       "39881          0      0          0         0       0          0          0   \n",
       "45572          0      0          0         0       0          0          0   \n",
       "15864          1      0          0         0       0          0          0   \n",
       "4910           0      1          1         0       0          0          0   \n",
       "\n",
       "       desire  ...  sadness  surprise  neutral  neutral_only  \\\n",
       "4095        0  ...        0         0        0         False   \n",
       "34642       1  ...        0         0        0         False   \n",
       "5142        1  ...        0         0        0         False   \n",
       "6323        0  ...        0         0        0         False   \n",
       "47759       0  ...        0         0        0         False   \n",
       "...       ...  ...      ...       ...      ...           ...   \n",
       "4205        0  ...        0         0        1          True   \n",
       "39881       0  ...        0         0        0         False   \n",
       "45572       0  ...        0         1        0         False   \n",
       "15864       0  ...        0         0        0         False   \n",
       "4910        0  ...        0         0        0         False   \n",
       "\n",
       "       neutral_and_other  neutral_above_1  length_text  positive_sum  \\\n",
       "4095                True            False           71             0   \n",
       "34642               True            False           51             3   \n",
       "5142                True            False          113             3   \n",
       "6323                True            False           94             2   \n",
       "47759               True            False           47             1   \n",
       "...                  ...              ...          ...           ...   \n",
       "4205               False            False           52             0   \n",
       "39881               True            False          119             1   \n",
       "45572               True            False          112             1   \n",
       "15864               True            False          111             2   \n",
       "4910                True            False           73             0   \n",
       "\n",
       "       negative_sum  neutral_sum  \n",
       "4095              1            0  \n",
       "34642             0            0  \n",
       "5142              0            0  \n",
       "6323              0            0  \n",
       "47759             0            0  \n",
       "...             ...          ...  \n",
       "4205              0            1  \n",
       "39881             1            0  \n",
       "45572             0            0  \n",
       "15864             1            0  \n",
       "4910              3            0  \n",
       "\n",
       "[51515 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_to_coarse = {\n",
    "    'admiration': 'positive',\n",
    "    'amusement': 'positive',\n",
    "    'anger': 'negative',\n",
    "    'annoyance': 'negative',\n",
    "    'approval': 'positive',\n",
    "    'caring': 'positive',\n",
    "    'confusion': 'negative',\n",
    "    'curiosity': 'positive',\n",
    "    'desire': 'positive',\n",
    "    'disappointment': 'negative',\n",
    "    'disapproval': 'negative',\n",
    "    'disgust': 'negative',\n",
    "    'embarrassment': 'negative',\n",
    "    'excitement': 'positive',\n",
    "    'fear': 'negative',\n",
    "    'gratitude': 'positive',\n",
    "    'grief': 'negative',\n",
    "    'joy': 'positive',\n",
    "    'love': 'positive',\n",
    "    'nervousness': 'negative',\n",
    "    'optimism': 'positive',\n",
    "    'pride': 'positive',\n",
    "    'realization': 'positive',\n",
    "    'relief': 'positive',\n",
    "    'remorse': 'negative',\n",
    "    'sadness': 'negative',\n",
    "    'surprise': 'positive',\n",
    "    'neutral': 'neutral'\n",
    "}\n",
    "\n",
    "# Create lists of emotions for each coarse category\n",
    "positive_emotions = [emotion for emotion, category in emotion_to_coarse.items() if category == 'positive']\n",
    "negative_emotions = [emotion for emotion, category in emotion_to_coarse.items() if category == 'negative']\n",
    "neutral_emotions =  [emotion for emotion, category in emotion_to_coarse.items() if category == 'neutral']\n",
    "\n",
    "# Sum the values for positive and negative emotions for each row\n",
    "train['positive_sum'] = train[positive_emotions].sum(axis=1)\n",
    "train['negative_sum'] = train[negative_emotions].sum(axis=1)\n",
    "train['neutral_sum'] = train[neutral_emotions].sum(axis=1)\n",
    "\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'> <class 'numpy.int64'>\n",
      "(51515, 200) (5724, 200)\n",
      "(51515, 28) (5724, 28)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train[0]), type(y_train[0]))\n",
    "print(type(X_train[0][0]), type(y_train[0][0]))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf ; print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 28  # Adjust based on your dataset\n",
    "embedding_dim = 256  # Embedding dimension\n",
    "max_sequence_length = 200  # Example sequence length, adjust as needed\n",
    "tokenizer_vocab_size = tokenizer.vocab_size  # Example vocabulary size, adjust as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convultional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 23:27:33.681663: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.681819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.681878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.681926: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.681973: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.682020: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.696485: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.696856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.697764: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.697781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-16 23:27:33.697840: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.697848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-16 23:27:33.697920: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.698342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-06-16 23:27:33.701433: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 23:27:33.701479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21770 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 256)          7813632   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 169, 128)          1048704   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 169, 128)          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 169, 2048)         264192    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 169, 1512)         3098088   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 169, 1024)         1549312   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 154, 128)          2097280   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 154, 128)          0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 154, 256)          33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 154, 128)          32896     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 147, 96)           98400     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 147, 96)           0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 147, 128)          12416     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 143, 64)           41024     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 136, 64)           32832     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 64)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16140196 (61.57 MB)\n",
      "Trainable params: 16140196 (61.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input, BatchNormalization, LSTM, Bidirectional, Reshape\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Number of classes for multi-label classification\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(max_sequence_length,)),\n",
    "    Embedding(input_dim=tokenizer_vocab_size, output_dim=embedding_dim),  # Embedding layer\n",
    "    Conv1D(filters=128, kernel_size=32, activation='relu'),  # Conv1D layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(2048, activation='relu'),  # Dense layer\n",
    "    Dense(1512, activation='relu'),  # Dense layer\n",
    "    Dense(1024, activation='relu'),  # Dense layer\n",
    "    Conv1D(filters=128, kernel_size=16, activation='relu'),  # Conv1D layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(256, activation='relu'),  # Dense layer\n",
    "    Dense(128, activation='relu'),  # Dense layer\n",
    "    Conv1D(filters=96, kernel_size=8, activation='relu'),  # Conv1D layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(128, activation='relu'),  # Dense layer\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu'),  # Conv1D layer\n",
    "    Conv1D(filters=64, kernel_size=8, activation='relu'),  # Conv1D layer\n",
    "    GlobalMaxPooling1D(),  # Global max pooling\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(128, activation='relu'),  # Dense layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(64, activation='relu'),  # Dense layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(num_classes, activation='sigmoid')  # Output layer for multi-label classification\n",
    "])\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)       [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)    (None, 200, 512)             1562726   ['input_16[0][0]']            \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " layer_normalization_60 (La  (None, 200, 512)             1024      ['embedding_15[0][0]']        \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (M  (None, 200, 512)             3150848   ['layer_normalization_60[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_60[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)        (None, 200, 512)             0         ['multi_head_attention_30[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (T  (None, 200, 512)             0         ['dropout_90[0][0]',          \n",
      " FOpLambda)                                                          'embedding_15[0][0]']        \n",
      "                                                                                                  \n",
      " layer_normalization_61 (La  (None, 200, 512)             1024      ['tf.__operators__.add_60[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_94 (Dense)            (None, 200, 384)             196992    ['layer_normalization_61[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)        (None, 200, 384)             0         ['dense_94[0][0]']            \n",
      "                                                                                                  \n",
      " dense_95 (Dense)            (None, 200, 512)             197120    ['dropout_91[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (T  (None, 200, 512)             0         ['dense_95[0][0]',            \n",
      " FOpLambda)                                                          'tf.__operators__.add_60[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_62 (La  (None, 200, 512)             1024      ['tf.__operators__.add_61[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_31 (M  (None, 200, 512)             3150848   ['layer_normalization_62[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_62[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)        (None, 200, 512)             0         ['multi_head_attention_31[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (T  (None, 200, 512)             0         ['dropout_92[0][0]',          \n",
      " FOpLambda)                                                          'tf.__operators__.add_61[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_63 (La  (None, 200, 512)             1024      ['tf.__operators__.add_62[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_96 (Dense)            (None, 200, 384)             196992    ['layer_normalization_63[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)        (None, 200, 384)             0         ['dense_96[0][0]']            \n",
      "                                                                                                  \n",
      " dense_97 (Dense)            (None, 200, 512)             197120    ['dropout_93[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (T  (None, 200, 512)             0         ['dense_97[0][0]',            \n",
      " FOpLambda)                                                          'tf.__operators__.add_62[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 512)                  0         ['tf.__operators__.add_63[0][0\n",
      " 5 (GlobalAveragePooling1D)                                         ]']                           \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)        (None, 512)                  0         ['global_average_pooling1d_15[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_98 (Dense)            (None, 1024)                 525312    ['dropout_94[0][0]']          \n",
      "                                                                                                  \n",
      " dense_99 (Dense)            (None, 256)                  262400    ['dense_98[0][0]']            \n",
      "                                                                                                  \n",
      " dense_100 (Dense)           (None, 128)                  32896     ['dense_99[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)        (None, 128)                  0         ['dense_100[0][0]']           \n",
      "                                                                                                  \n",
      " dense_101 (Dense)           (None, 28)                   3612      ['dropout_95[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23545500 (89.82 MB)\n",
      "Trainable params: 23545500 (89.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LayerNormalization, Embedding, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 512  # Embedding dimension\n",
    "max_sequence_length = 200  # Example sequence length, adjust as needed\n",
    "tokenizer_vocab_size = tokenizer.vocab_size  # Example vocabulary size, adjust as needed\n",
    "num_classes = 28  # Adjust based on your dataset\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def build_transformer_model():\n",
    "    inputs = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(input_dim=tokenizer_vocab_size, output_dim=embedding_dim)(inputs)\n",
    "    x = transformer_encoder(embedding_layer, head_size=384, num_heads=4, ff_dim=384, dropout=0.1)\n",
    "    x = transformer_encoder(x,               head_size=384, num_heads=4, ff_dim=384, dropout=0.1)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_transformer_model()\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "[[0.4060692  0.30911326 0.30569783 0.32164896 0.18355535 0.33891717\n",
      "  0.51138616 0.5754442  0.74831736 0.6371823  0.4463154  0.5330856\n",
      "  0.4585348  0.8208208  0.4039716  0.42799556 0.4484758  0.5489841\n",
      "  0.31696117 0.3885523  0.5735042  0.55337226 0.6397506  0.75216395\n",
      "  0.7138752  0.39692912 0.51954585 0.4933341 ]]\n",
      "['desire', 'excitement', 'relief']\n",
      "['disapproval']\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_train[0:1])\n",
    "decoded = decode_logits(result[0], k=3, alphabetic_sort=True)\n",
    "y_train[0]\n",
    "\n",
    "print(result)\n",
    "print(decoded)\n",
    "print(decode_emotions_to_string(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 200, 200)             6104400   ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 200, 200)             0         ['embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 40000)                0         ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 3)                    120003    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 40003)                0         ['dense_12[0][0]',            \n",
      "                                                                     'flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 128)                  5120512   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 128)                  0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 28)                   3612      ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11348527 (43.29 MB)\n",
      "Trainable params: 11348527 (43.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, LSTM, Dropout, concatenate, Flatten\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(input_dim=tokenizer_vocab_size, output_dim=max_sequence_length)(input_layer)\n",
    "dropout_layer = Dropout(rate=0.5)(embedding_layer)\n",
    "flat_layer = Flatten()(dropout_layer)\n",
    "\n",
    "# Coarse-grained classification layer\n",
    "coarse_output_layer = Dense(units=3, activation='softmax')(flat_layer)\n",
    "\n",
    "# Fine-grained classification layer\n",
    "fine_output_layer = Dense(units=128, activation='relu')( concatenate([coarse_output_layer, flat_layer]))\n",
    "fine_output_layer = Dropout(rate=0.5)(fine_output_layer)\n",
    "fine_output_layer = Dense(units=28, activation='sigmoid')(fine_output_layer)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=fine_output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51515, 200), (51515, 28))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 0.603615954255718, 1: 2.912755852086396}, 1: {0: 0.5488610454090221, 1: 5.616550370693415}, 2: {0: 0.5534843243010937, 1: 5.1742667738047405}, 3: {0: 0.6034603940678959, 1: 2.916383605072464}, 4: {0: 0.6444369386274362, 1: 2.2308591720076216}, 5: {0: 0.5377685450028186, 1: 7.119264787175235}, 6: {0: 0.5479736198276779, 1: 5.7111973392461195}, 7: {0: 0.5562574236043624, 1: 4.9438579654510555}, 8: {0: 0.5229099841650088, 1: 11.412272928666372}, 9: {0: 0.5569309606694198, 1: 4.891283706798329}, 10: {0: 0.5718551574086408, 1: 3.9792213811215817}, 11: {0: 0.5267382413087934, 1: 9.849904397705545}, 12: {0: 0.511629985698395, 1: 21.996157130657558}, 13: {0: 0.5321027950503027, 1: 8.287483912483912}, 14: {0: 0.5142757312568633, 1: 18.012237762237763}, 15: {0: 0.5437283627459258, 1: 6.2171132029930005}, 16: {0: 0.5027913876905659, 1: 90.06118881118881}, 17: {0: 0.5415221276148429, 1: 6.520886075949367}, 18: {0: 0.5332153355690804, 1: 8.02664381427236}, 19: {0: 0.507717022786407, 1: 32.895913154533844}, 20: {0: 0.5430176666526121, 1: 6.311565792697868}, 21: {0: 0.505058922723975, 1: 49.917635658914726}, 22: {0: 0.5464506958587916, 1: 5.8820506965060515}, 23: {0: 0.5052669779120404, 1: 47.965549348230915}, 24: {0: 0.5092327158419169, 1: 27.57762312633833}, 25: {0: 0.526986107985351, 1: 9.764025777103866}, 26: {0: 0.5231011372867588, 1: 11.321978021978023}, 27: {0: 0.5399668776990483, 1: 6.755179648570679}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_train is your multi-label binary matrix (samples x labels)\n",
    "# Flatten y_train to a 1D array for each label\n",
    "class_weights = []\n",
    "for i in range(y_train.shape[1]):\n",
    "    class_weight = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=y_train[:, i])\n",
    "    class_weights.append(class_weight)\n",
    "\n",
    "# Convert to a dictionary format suitable for Keras\n",
    "class_weight_dict = {i: {0: class_weights[i][0], 1: class_weights[i][1]} for i in range(len(class_weights))}\n",
    "\n",
    "print(class_weight_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt    \n",
    "import datetime\n",
    "from metrics import all_metrics, cosine_similarity_loss\n",
    "\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, embeddings_freq=1)\n",
    "\n",
    "\n",
    "# Learning rate scheduler callback\n",
    "\n",
    "def scheduler(epoch, lr, warmup=3, steps=10):\n",
    "    if epoch < 3:\n",
    "        return lr * 1.3\n",
    "    elif epoch % steps == 0:\n",
    "        return lr * 0.9\n",
    "    else:\n",
    "        return lr * 0.99\n",
    "\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "initial_lr = 1e-4\n",
    "\n",
    "adam  = keras.optimizers.Adam( learning_rate=initial_lr, weight_decay=0.01)\n",
    "adamW = keras.optimizers.AdamW(learning_rate=initial_lr, weight_decay=0.01)\n",
    "sgd =   keras.optimizers.SGD(  learning_rate=initial_lr, momentum=0.9)\n",
    "rms =   keras.optimizers.RMSprop(learning_rate=initial_lr, rho=0.9)\n",
    "\n",
    "\n",
    "# Usage in model compilation and training\n",
    "model.compile(optimizer=adam, loss=cosine_similarity_loss, metrics=all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "68/68 [==============================] - 54s 702ms/step - loss: 0.1783 - f1_score: 0.3948 - auc: 0.8297 - precision: 0.7243 - recall: 0.2512 - R2: 0.2261 - binary_crossentropy: 0.1784 - false_positives: 10137.0000 - false_negatives: 79360.0000 - true_positives: 26627.0000 - true_negatives: 1326296.0000 - precision_over_recall: 0.4580 - roc: 0.8297 - val_loss: 0.1933 - val_f1_score: 0.3491 - val_auc: 0.7783 - val_precision: 0.6819 - val_recall: 0.2128 - val_R2: 0.1791 - val_binary_crossentropy: 0.1934 - val_false_positives: 1166.0000 - val_false_negatives: 9243.0000 - val_true_positives: 2499.0000 - val_true_negatives: 147364.0000 - val_precision_over_recall: 0.3757 - val_roc: 0.7783\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 48s 701ms/step - loss: 0.1760 - f1_score: 0.3999 - auc: 0.8362 - precision: 0.7277 - recall: 0.2621 - R2: 0.2343 - binary_crossentropy: 0.1760 - false_positives: 10393.0000 - false_negatives: 78213.0000 - true_positives: 27774.0000 - true_negatives: 1326040.0000 - precision_over_recall: 0.4677 - roc: 0.8362 - val_loss: 0.1938 - val_f1_score: 0.3514 - val_auc: 0.7797 - val_precision: 0.6724 - val_recall: 0.2204 - val_R2: 0.1793 - val_binary_crossentropy: 0.1941 - val_false_positives: 1261.0000 - val_false_negatives: 9154.0000 - val_true_positives: 2588.0000 - val_true_negatives: 147269.0000 - val_precision_over_recall: 0.3857 - val_roc: 0.7797\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 48s 707ms/step - loss: 0.1745 - f1_score: 0.4054 - auc: 0.8402 - precision: 0.7306 - recall: 0.2700 - R2: 0.2397 - binary_crossentropy: 0.1743 - false_positives: 10551.0000 - false_negatives: 77375.0000 - true_positives: 28612.0000 - true_negatives: 1325882.0000 - precision_over_recall: 0.4783 - roc: 0.8402 - val_loss: 0.1946 - val_f1_score: 0.3502 - val_auc: 0.7817 - val_precision: 0.6607 - val_recall: 0.2219 - val_R2: 0.1770 - val_binary_crossentropy: 0.1947 - val_false_positives: 1338.0000 - val_false_negatives: 9137.0000 - val_true_positives: 2605.0000 - val_true_negatives: 147192.0000 - val_precision_over_recall: 0.3836 - val_roc: 0.7817\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 48s 710ms/step - loss: 0.1737 - f1_score: 0.4070 - auc: 0.8418 - precision: 0.7291 - recall: 0.2755 - R2: 0.2434 - binary_crossentropy: 0.1739 - false_positives: 10851.0000 - false_negatives: 76787.0000 - true_positives: 29200.0000 - true_negatives: 1325582.0000 - precision_over_recall: 0.4870 - roc: 0.8418 - val_loss: 0.1953 - val_f1_score: 0.3507 - val_auc: 0.7813 - val_precision: 0.6649 - val_recall: 0.2242 - val_R2: 0.1780 - val_binary_crossentropy: 0.1955 - val_false_positives: 1327.0000 - val_false_negatives: 9109.0000 - val_true_positives: 2633.0000 - val_true_negatives: 147203.0000 - val_precision_over_recall: 0.3829 - val_roc: 0.7813\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 48s 708ms/step - loss: 0.1730 - f1_score: 0.4077 - auc: 0.8433 - precision: 0.7270 - recall: 0.2786 - R2: 0.2457 - binary_crossentropy: 0.1730 - false_positives: 11088.0000 - false_negatives: 76462.0000 - true_positives: 29525.0000 - true_negatives: 1325345.0000 - precision_over_recall: 0.4862 - roc: 0.8433 - val_loss: 0.1962 - val_f1_score: 0.3510 - val_auc: 0.7809 - val_precision: 0.6656 - val_recall: 0.2230 - val_R2: 0.1748 - val_binary_crossentropy: 0.1964 - val_false_positives: 1316.0000 - val_false_negatives: 9123.0000 - val_true_positives: 2619.0000 - val_true_negatives: 147214.0000 - val_precision_over_recall: 0.3786 - val_roc: 0.7809\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 47s 698ms/step - loss: 0.1721 - f1_score: 0.4103 - auc: 0.8461 - precision: 0.7284 - recall: 0.2826 - R2: 0.2483 - binary_crossentropy: 0.1722 - false_positives: 11170.0000 - false_negatives: 76035.0000 - true_positives: 29952.0000 - true_negatives: 1325263.0000 - precision_over_recall: 0.4928 - roc: 0.8461 - val_loss: 0.1973 - val_f1_score: 0.3473 - val_auc: 0.7798 - val_precision: 0.6746 - val_recall: 0.2098 - val_R2: 0.1736 - val_binary_crossentropy: 0.1974 - val_false_positives: 1188.0000 - val_false_negatives: 9279.0000 - val_true_positives: 2463.0000 - val_true_negatives: 147342.0000 - val_precision_over_recall: 0.3744 - val_roc: 0.7798\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 47s 695ms/step - loss: 0.1712 - f1_score: 0.4131 - auc: 0.8477 - precision: 0.7306 - recall: 0.2866 - R2: 0.2524 - binary_crossentropy: 0.1714 - false_positives: 11198.0000 - false_negatives: 75616.0000 - true_positives: 30371.0000 - true_negatives: 1325235.0000 - precision_over_recall: 0.5015 - roc: 0.8477 - val_loss: 0.1963 - val_f1_score: 0.3497 - val_auc: 0.7825 - val_precision: 0.6469 - val_recall: 0.2289 - val_R2: 0.1738 - val_binary_crossentropy: 0.1965 - val_false_positives: 1467.0000 - val_false_negatives: 9054.0000 - val_true_positives: 2688.0000 - val_true_negatives: 147063.0000 - val_precision_over_recall: 0.3735 - val_roc: 0.7825\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 48s 708ms/step - loss: 0.1703 - f1_score: 0.4157 - auc: 0.8505 - precision: 0.7332 - recall: 0.2898 - R2: 0.2567 - binary_crossentropy: 0.1705 - false_positives: 11176.0000 - false_negatives: 75274.0000 - true_positives: 30713.0000 - true_negatives: 1325257.0000 - precision_over_recall: 0.5088 - roc: 0.8505 - val_loss: 0.1965 - val_f1_score: 0.3543 - val_auc: 0.7806 - val_precision: 0.6418 - val_recall: 0.2351 - val_R2: 0.1748 - val_binary_crossentropy: 0.1966 - val_false_positives: 1541.0000 - val_false_negatives: 8981.0000 - val_true_positives: 2761.0000 - val_true_negatives: 146989.0000 - val_precision_over_recall: 0.3799 - val_roc: 0.7806\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.1695 - f1_score: 0.4183 - auc: 0.8516 - precision: 0.7326 - recall: 0.2947 - R2: 0.2601 - binary_crossentropy: 0.1696 - false_positives: 11401.0000 - false_negatives: 74756.0000 - true_positives: 31231.0000 - true_negatives: 1325032.0000 - precision_over_recall: 0.5182 - roc: 0.8516 - val_loss: 0.1961 - val_f1_score: 0.3504 - val_auc: 0.7814 - val_precision: 0.6463 - val_recall: 0.2350 - val_R2: 0.1745 - val_binary_crossentropy: 0.1961 - val_false_positives: 1510.0000 - val_false_negatives: 8983.0000 - val_true_positives: 2759.0000 - val_true_negatives: 147020.0000 - val_precision_over_recall: 0.3759 - val_roc: 0.7814\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 49s 722ms/step - loss: 0.1695 - f1_score: 0.4180 - auc: 0.8516 - precision: 0.7347 - recall: 0.2942 - R2: 0.2604 - binary_crossentropy: 0.1693 - false_positives: 11259.0000 - false_negatives: 74803.0000 - true_positives: 31184.0000 - true_negatives: 1325174.0000 - precision_over_recall: 0.5138 - roc: 0.8516 - val_loss: 0.2002 - val_f1_score: 0.3472 - val_auc: 0.7765 - val_precision: 0.6577 - val_recall: 0.2129 - val_R2: 0.1688 - val_binary_crossentropy: 0.2001 - val_false_positives: 1301.0000 - val_false_negatives: 9242.0000 - val_true_positives: 2500.0000 - val_true_negatives: 147229.0000 - val_precision_over_recall: 0.3686 - val_roc: 0.7765\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 49s 726ms/step - loss: 0.1696 - f1_score: 0.4186 - auc: 0.8513 - precision: 0.7298 - recall: 0.2965 - R2: 0.2599 - binary_crossentropy: 0.1697 - false_positives: 11637.0000 - false_negatives: 74561.0000 - true_positives: 31426.0000 - true_negatives: 1324796.0000 - precision_over_recall: 0.5118 - roc: 0.8513 - val_loss: 0.1997 - val_f1_score: 0.3480 - val_auc: 0.7773 - val_precision: 0.6356 - val_recall: 0.2308 - val_R2: 0.1671 - val_binary_crossentropy: 0.1999 - val_false_positives: 1554.0000 - val_false_negatives: 9032.0000 - val_true_positives: 2710.0000 - val_true_negatives: 146976.0000 - val_precision_over_recall: 0.3731 - val_roc: 0.7773\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 49s 727ms/step - loss: 0.1685 - f1_score: 0.4202 - auc: 0.8549 - precision: 0.7321 - recall: 0.3015 - R2: 0.2636 - binary_crossentropy: 0.1686 - false_positives: 11690.0000 - false_negatives: 74036.0000 - true_positives: 31951.0000 - true_negatives: 1324743.0000 - precision_over_recall: 0.5178 - roc: 0.8549 - val_loss: 0.1979 - val_f1_score: 0.3541 - val_auc: 0.7811 - val_precision: 0.6462 - val_recall: 0.2338 - val_R2: 0.1730 - val_binary_crossentropy: 0.1982 - val_false_positives: 1503.0000 - val_false_negatives: 8997.0000 - val_true_positives: 2745.0000 - val_true_negatives: 147027.0000 - val_precision_over_recall: 0.3804 - val_roc: 0.7811\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 50s 729ms/step - loss: 0.1677 - f1_score: 0.4214 - auc: 0.8559 - precision: 0.7335 - recall: 0.3033 - R2: 0.2670 - binary_crossentropy: 0.1676 - false_positives: 11679.0000 - false_negatives: 73838.0000 - true_positives: 32149.0000 - true_negatives: 1324754.0000 - precision_over_recall: 0.5243 - roc: 0.8559 - val_loss: 0.1995 - val_f1_score: 0.3478 - val_auc: 0.7805 - val_precision: 0.6397 - val_recall: 0.2300 - val_R2: 0.1729 - val_binary_crossentropy: 0.1996 - val_false_positives: 1521.0000 - val_false_negatives: 9041.0000 - val_true_positives: 2701.0000 - val_true_negatives: 147009.0000 - val_precision_over_recall: 0.3793 - val_roc: 0.7805\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 50s 730ms/step - loss: 0.1664 - f1_score: 0.4250 - auc: 0.8593 - precision: 0.7344 - recall: 0.3081 - R2: 0.2714 - binary_crossentropy: 0.1663 - false_positives: 11808.0000 - false_negatives: 73331.0000 - true_positives: 32656.0000 - true_negatives: 1324625.0000 - precision_over_recall: 0.5332 - roc: 0.8593 - val_loss: 0.1993 - val_f1_score: 0.3520 - val_auc: 0.7813 - val_precision: 0.6380 - val_recall: 0.2425 - val_R2: 0.1741 - val_binary_crossentropy: 0.1994 - val_false_positives: 1616.0000 - val_false_negatives: 8894.0000 - val_true_positives: 2848.0000 - val_true_negatives: 146914.0000 - val_precision_over_recall: 0.3792 - val_roc: 0.7813\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 50s 730ms/step - loss: 0.1653 - f1_score: 0.4269 - auc: 0.8623 - precision: 0.7359 - recall: 0.3141 - R2: 0.2757 - binary_crossentropy: 0.1651 - false_positives: 11944.0000 - false_negatives: 72700.0000 - true_positives: 33287.0000 - true_negatives: 1324489.0000 - precision_over_recall: 0.5393 - roc: 0.8623 - val_loss: 0.2009 - val_f1_score: 0.3510 - val_auc: 0.7791 - val_precision: 0.6306 - val_recall: 0.2414 - val_R2: 0.1726 - val_binary_crossentropy: 0.2012 - val_false_positives: 1660.0000 - val_false_negatives: 8908.0000 - val_true_positives: 2834.0000 - val_true_negatives: 146870.0000 - val_precision_over_recall: 0.3799 - val_roc: 0.7791\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 54s 788ms/step - loss: 0.1650 - f1_score: 0.4287 - auc: 0.8621 - precision: 0.7375 - recall: 0.3167 - R2: 0.2780 - binary_crossentropy: 0.1651 - false_positives: 11950.0000 - false_negatives: 72417.0000 - true_positives: 33570.0000 - true_negatives: 1324483.0000 - precision_over_recall: 0.5405 - roc: 0.8621 - val_loss: 0.1992 - val_f1_score: 0.3490 - val_auc: 0.7797 - val_precision: 0.6399 - val_recall: 0.2293 - val_R2: 0.1703 - val_binary_crossentropy: 0.1995 - val_false_positives: 1515.0000 - val_false_negatives: 9050.0000 - val_true_positives: 2692.0000 - val_true_negatives: 147015.0000 - val_precision_over_recall: 0.3814 - val_roc: 0.7797\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 53s 777ms/step - loss: 0.1647 - f1_score: 0.4292 - auc: 0.8635 - precision: 0.7373 - recall: 0.3165 - R2: 0.2785 - binary_crossentropy: 0.1644 - false_positives: 11954.0000 - false_negatives: 72439.0000 - true_positives: 33548.0000 - true_negatives: 1324479.0000 - precision_over_recall: 0.5418 - roc: 0.8635 - val_loss: 0.2021 - val_f1_score: 0.3561 - val_auc: 0.7774 - val_precision: 0.6379 - val_recall: 0.2384 - val_R2: 0.1727 - val_binary_crossentropy: 0.2022 - val_false_positives: 1589.0000 - val_false_negatives: 8943.0000 - val_true_positives: 2799.0000 - val_true_negatives: 146941.0000 - val_precision_over_recall: 0.3727 - val_roc: 0.7774\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 0.1639 - f1_score: 0.4319 - auc: 0.8656 - precision: 0.7393 - recall: 0.3195 - R2: 0.2817 - binary_crossentropy: 0.1641 - false_positives: 11940.0000 - false_negatives: 72120.0000 - true_positives: 33867.0000 - true_negatives: 1324493.0000 - precision_over_recall: 0.5491 - roc: 0.8656 - val_loss: 0.2023 - val_f1_score: 0.3533 - val_auc: 0.7778 - val_precision: 0.6383 - val_recall: 0.2397 - val_R2: 0.1703 - val_binary_crossentropy: 0.2022 - val_false_positives: 1595.0000 - val_false_negatives: 8927.0000 - val_true_positives: 2815.0000 - val_true_negatives: 146935.0000 - val_precision_over_recall: 0.3787 - val_roc: 0.7778\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 49s 728ms/step - loss: 0.1632 - f1_score: 0.4330 - auc: 0.8667 - precision: 0.7384 - recall: 0.3234 - R2: 0.2836 - binary_crossentropy: 0.1634 - false_positives: 12145.0000 - false_negatives: 71706.0000 - true_positives: 34281.0000 - true_negatives: 1324288.0000 - precision_over_recall: 0.5491 - roc: 0.8667 - val_loss: 0.2026 - val_f1_score: 0.3486 - val_auc: 0.7786 - val_precision: 0.6252 - val_recall: 0.2313 - val_R2: 0.1669 - val_binary_crossentropy: 0.2026 - val_false_positives: 1628.0000 - val_false_negatives: 9026.0000 - val_true_positives: 2716.0000 - val_true_negatives: 146902.0000 - val_precision_over_recall: 0.3753 - val_roc: 0.7786\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 50s 731ms/step - loss: 0.1626 - f1_score: 0.4354 - auc: 0.8686 - precision: 0.7427 - recall: 0.3259 - R2: 0.2868 - binary_crossentropy: 0.1624 - false_positives: 11964.0000 - false_negatives: 71451.0000 - true_positives: 34536.0000 - true_negatives: 1324469.0000 - precision_over_recall: 0.5555 - roc: 0.8686 - val_loss: 0.2020 - val_f1_score: 0.3492 - val_auc: 0.7788 - val_precision: 0.6192 - val_recall: 0.2457 - val_R2: 0.1675 - val_binary_crossentropy: 0.2020 - val_false_positives: 1774.0000 - val_false_negatives: 8857.0000 - val_true_positives: 2885.0000 - val_true_negatives: 146756.0000 - val_precision_over_recall: 0.3731 - val_roc: 0.7788\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 50s 734ms/step - loss: 0.1621 - f1_score: 0.4352 - auc: 0.8686 - precision: 0.7388 - recall: 0.3308 - R2: 0.2886 - binary_crossentropy: 0.1623 - false_positives: 12398.0000 - false_negatives: 70924.0000 - true_positives: 35063.0000 - true_negatives: 1324035.0000 - precision_over_recall: 0.5623 - roc: 0.8686 - val_loss: 0.2029 - val_f1_score: 0.3498 - val_auc: 0.7751 - val_precision: 0.6363 - val_recall: 0.2316 - val_R2: 0.1675 - val_binary_crossentropy: 0.2028 - val_false_positives: 1554.0000 - val_false_negatives: 9023.0000 - val_true_positives: 2719.0000 - val_true_negatives: 146976.0000 - val_precision_over_recall: 0.3746 - val_roc: 0.7751\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 50s 733ms/step - loss: 0.1614 - f1_score: 0.4378 - auc: 0.8702 - precision: 0.7411 - recall: 0.3325 - R2: 0.2918 - binary_crossentropy: 0.1613 - false_positives: 12311.0000 - false_negatives: 70743.0000 - true_positives: 35244.0000 - true_negatives: 1324122.0000 - precision_over_recall: 0.5634 - roc: 0.8702 - val_loss: 0.2075 - val_f1_score: 0.3451 - val_auc: 0.7761 - val_precision: 0.6248 - val_recall: 0.2259 - val_R2: 0.1581 - val_binary_crossentropy: 0.2074 - val_false_positives: 1593.0000 - val_false_negatives: 9089.0000 - val_true_positives: 2653.0000 - val_true_negatives: 146937.0000 - val_precision_over_recall: 0.3680 - val_roc: 0.7761\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 50s 735ms/step - loss: 0.1612 - f1_score: 0.4385 - auc: 0.8706 - precision: 0.7425 - recall: 0.3332 - R2: 0.2926 - binary_crossentropy: 0.1611 - false_positives: 12246.0000 - false_negatives: 70667.0000 - true_positives: 35320.0000 - true_negatives: 1324187.0000 - precision_over_recall: 0.5641 - roc: 0.8706 - val_loss: 0.2062 - val_f1_score: 0.3460 - val_auc: 0.7762 - val_precision: 0.6149 - val_recall: 0.2420 - val_R2: 0.1608 - val_binary_crossentropy: 0.2063 - val_false_positives: 1779.0000 - val_false_negatives: 8901.0000 - val_true_positives: 2841.0000 - val_true_negatives: 146751.0000 - val_precision_over_recall: 0.3712 - val_roc: 0.7762\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 50s 735ms/step - loss: 0.1601 - f1_score: 0.4419 - auc: 0.8730 - precision: 0.7455 - recall: 0.3392 - R2: 0.2963 - binary_crossentropy: 0.1602 - false_positives: 12274.0000 - false_negatives: 70034.0000 - true_positives: 35953.0000 - true_negatives: 1324159.0000 - precision_over_recall: 0.5706 - roc: 0.8730 - val_loss: 0.2052 - val_f1_score: 0.3492 - val_auc: 0.7762 - val_precision: 0.6256 - val_recall: 0.2415 - val_R2: 0.1645 - val_binary_crossentropy: 0.2054 - val_false_positives: 1697.0000 - val_false_negatives: 8906.0000 - val_true_positives: 2836.0000 - val_true_negatives: 146833.0000 - val_precision_over_recall: 0.3749 - val_roc: 0.7762\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 50s 735ms/step - loss: 0.1596 - f1_score: 0.4420 - auc: 0.8743 - precision: 0.7459 - recall: 0.3409 - R2: 0.2981 - binary_crossentropy: 0.1595 - false_positives: 12306.0000 - false_negatives: 69860.0000 - true_positives: 36127.0000 - true_negatives: 1324127.0000 - precision_over_recall: 0.5728 - roc: 0.8743 - val_loss: 0.2053 - val_f1_score: 0.3481 - val_auc: 0.7744 - val_precision: 0.6090 - val_recall: 0.2495 - val_R2: 0.1640 - val_binary_crossentropy: 0.2053 - val_false_positives: 1881.0000 - val_false_negatives: 8812.0000 - val_true_positives: 2930.0000 - val_true_negatives: 146649.0000 - val_precision_over_recall: 0.3775 - val_roc: 0.7744\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 50s 735ms/step - loss: 0.1594 - f1_score: 0.4433 - auc: 0.8743 - precision: 0.7443 - recall: 0.3438 - R2: 0.2996 - binary_crossentropy: 0.1592 - false_positives: 12514.0000 - false_negatives: 69553.0000 - true_positives: 36434.0000 - true_negatives: 1323919.0000 - precision_over_recall: 0.5777 - roc: 0.8743 - val_loss: 0.2052 - val_f1_score: 0.3529 - val_auc: 0.7780 - val_precision: 0.6149 - val_recall: 0.2523 - val_R2: 0.1677 - val_binary_crossentropy: 0.2053 - val_false_positives: 1855.0000 - val_false_negatives: 8780.0000 - val_true_positives: 2962.0000 - val_true_negatives: 146675.0000 - val_precision_over_recall: 0.3797 - val_roc: 0.7780\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.1587 - f1_score: 0.4448 - auc: 0.8761 - precision: 0.7447 - recall: 0.3469 - R2: 0.3019 - binary_crossentropy: 0.1586 - false_positives: 12605.0000 - false_negatives: 69225.0000 - true_positives: 36762.0000 - true_negatives: 1323828.0000 - precision_over_recall: 0.5795 - roc: 0.8761 - val_loss: 0.2052 - val_f1_score: 0.3513 - val_auc: 0.7755 - val_precision: 0.6249 - val_recall: 0.2369 - val_R2: 0.1604 - val_binary_crossentropy: 0.2052 - val_false_positives: 1670.0000 - val_false_negatives: 8960.0000 - val_true_positives: 2782.0000 - val_true_negatives: 146860.0000 - val_precision_over_recall: 0.3676 - val_roc: 0.7755\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 54s 799ms/step - loss: 0.1581 - f1_score: 0.4469 - auc: 0.8768 - precision: 0.7471 - recall: 0.3482 - R2: 0.3037 - binary_crossentropy: 0.1582 - false_positives: 12495.0000 - false_negatives: 69084.0000 - true_positives: 36903.0000 - true_negatives: 1323938.0000 - precision_over_recall: 0.5879 - roc: 0.8768 - val_loss: 0.2050 - val_f1_score: 0.3479 - val_auc: 0.7751 - val_precision: 0.6140 - val_recall: 0.2448 - val_R2: 0.1627 - val_binary_crossentropy: 0.2052 - val_false_positives: 1807.0000 - val_false_negatives: 8868.0000 - val_true_positives: 2874.0000 - val_true_negatives: 146723.0000 - val_precision_over_recall: 0.3702 - val_roc: 0.7751\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 53s 780ms/step - loss: 0.1576 - f1_score: 0.4460 - auc: 0.8766 - precision: 0.7449 - recall: 0.3497 - R2: 0.3055 - binary_crossentropy: 0.1574 - false_positives: 12693.0000 - false_negatives: 68925.0000 - true_positives: 37062.0000 - true_negatives: 1323740.0000 - precision_over_recall: 0.5876 - roc: 0.8766 - val_loss: 0.2105 - val_f1_score: 0.3433 - val_auc: 0.7734 - val_precision: 0.6065 - val_recall: 0.2400 - val_R2: 0.1558 - val_binary_crossentropy: 0.2106 - val_false_positives: 1828.0000 - val_false_negatives: 8924.0000 - val_true_positives: 2818.0000 - val_true_negatives: 146702.0000 - val_precision_over_recall: 0.3747 - val_roc: 0.7734\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 0.1569 - f1_score: 0.4488 - auc: 0.8785 - precision: 0.7503 - recall: 0.3544 - R2: 0.3085 - binary_crossentropy: 0.1569 - false_positives: 12501.0000 - false_negatives: 68426.0000 - true_positives: 37561.0000 - true_negatives: 1323932.0000 - precision_over_recall: 0.5956 - roc: 0.8785 - val_loss: 0.2098 - val_f1_score: 0.3487 - val_auc: 0.7758 - val_precision: 0.6007 - val_recall: 0.2649 - val_R2: 0.1618 - val_binary_crossentropy: 0.2101 - val_false_positives: 2067.0000 - val_false_negatives: 8632.0000 - val_true_positives: 3110.0000 - val_true_negatives: 146463.0000 - val_precision_over_recall: 0.3743 - val_roc: 0.7758\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 50s 743ms/step - loss: 0.1562 - f1_score: 0.4501 - auc: 0.8804 - precision: 0.7510 - recall: 0.3579 - R2: 0.3112 - binary_crossentropy: 0.1563 - false_positives: 12579.0000 - false_negatives: 68051.0000 - true_positives: 37936.0000 - true_negatives: 1323854.0000 - precision_over_recall: 0.5950 - roc: 0.8804 - val_loss: 0.2065 - val_f1_score: 0.3486 - val_auc: 0.7750 - val_precision: 0.6110 - val_recall: 0.2431 - val_R2: 0.1605 - val_binary_crossentropy: 0.2067 - val_false_positives: 1817.0000 - val_false_negatives: 8888.0000 - val_true_positives: 2854.0000 - val_true_negatives: 146713.0000 - val_precision_over_recall: 0.3746 - val_roc: 0.7750\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 51s 744ms/step - loss: 0.1557 - f1_score: 0.4517 - auc: 0.8816 - precision: 0.7516 - recall: 0.3572 - R2: 0.3129 - binary_crossentropy: 0.1557 - false_positives: 12514.0000 - false_negatives: 68130.0000 - true_positives: 37857.0000 - true_negatives: 1323919.0000 - precision_over_recall: 0.6027 - roc: 0.8816 - val_loss: 0.2098 - val_f1_score: 0.3501 - val_auc: 0.7724 - val_precision: 0.6046 - val_recall: 0.2501 - val_R2: 0.1590 - val_binary_crossentropy: 0.2101 - val_false_positives: 1921.0000 - val_false_negatives: 8805.0000 - val_true_positives: 2937.0000 - val_true_negatives: 146609.0000 - val_precision_over_recall: 0.3740 - val_roc: 0.7724\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 51s 747ms/step - loss: 0.1552 - f1_score: 0.4525 - auc: 0.8814 - precision: 0.7507 - recall: 0.3640 - R2: 0.3141 - binary_crossentropy: 0.1552 - false_positives: 12814.0000 - false_negatives: 67411.0000 - true_positives: 38576.0000 - true_negatives: 1323619.0000 - precision_over_recall: 0.5998 - roc: 0.8814 - val_loss: 0.2095 - val_f1_score: 0.3484 - val_auc: 0.7758 - val_precision: 0.6069 - val_recall: 0.2494 - val_R2: 0.1569 - val_binary_crossentropy: 0.2098 - val_false_positives: 1897.0000 - val_false_negatives: 8813.0000 - val_true_positives: 2929.0000 - val_true_negatives: 146633.0000 - val_precision_over_recall: 0.3703 - val_roc: 0.7758\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 51s 748ms/step - loss: 0.1547 - f1_score: 0.4546 - auc: 0.8836 - precision: 0.7517 - recall: 0.3649 - R2: 0.3164 - binary_crossentropy: 0.1552 - false_positives: 12775.0000 - false_negatives: 67308.0000 - true_positives: 38679.0000 - true_negatives: 1323658.0000 - precision_over_recall: 0.6092 - roc: 0.8836 - val_loss: 0.2112 - val_f1_score: 0.3484 - val_auc: 0.7727 - val_precision: 0.6047 - val_recall: 0.2483 - val_R2: 0.1584 - val_binary_crossentropy: 0.2113 - val_false_positives: 1906.0000 - val_false_negatives: 8826.0000 - val_true_positives: 2916.0000 - val_true_negatives: 146624.0000 - val_precision_over_recall: 0.3698 - val_roc: 0.7727\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 61s 898ms/step - loss: 0.1548 - f1_score: 0.4542 - auc: 0.8833 - precision: 0.7521 - recall: 0.3642 - R2: 0.3165 - binary_crossentropy: 0.1549 - false_positives: 12719.0000 - false_negatives: 67391.0000 - true_positives: 38596.0000 - true_negatives: 1323714.0000 - precision_over_recall: 0.6102 - roc: 0.8833 - val_loss: 0.2093 - val_f1_score: 0.3491 - val_auc: 0.7752 - val_precision: 0.5862 - val_recall: 0.2595 - val_R2: 0.1556 - val_binary_crossentropy: 0.2093 - val_false_positives: 2151.0000 - val_false_negatives: 8695.0000 - val_true_positives: 3047.0000 - val_true_negatives: 146379.0000 - val_precision_over_recall: 0.3764 - val_roc: 0.7752\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 50s 742ms/step - loss: 0.1545 - f1_score: 0.4542 - auc: 0.8836 - precision: 0.7510 - recall: 0.3662 - R2: 0.3183 - binary_crossentropy: 0.1547 - false_positives: 12870.0000 - false_negatives: 67176.0000 - true_positives: 38811.0000 - true_negatives: 1323563.0000 - precision_over_recall: 0.6097 - roc: 0.8836 - val_loss: 0.2098 - val_f1_score: 0.3474 - val_auc: 0.7718 - val_precision: 0.5931 - val_recall: 0.2464 - val_R2: 0.1552 - val_binary_crossentropy: 0.2098 - val_false_positives: 1985.0000 - val_false_negatives: 8849.0000 - val_true_positives: 2893.0000 - val_true_negatives: 146545.0000 - val_precision_over_recall: 0.3680 - val_roc: 0.7718\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 0.1538 - f1_score: 0.4561 - auc: 0.8846 - precision: 0.7543 - recall: 0.3676 - R2: 0.3203 - binary_crossentropy: 0.1538 - false_positives: 12692.0000 - false_negatives: 67031.0000 - true_positives: 38956.0000 - true_negatives: 1323741.0000 - precision_over_recall: 0.6174 - roc: 0.8846 - val_loss: 0.2097 - val_f1_score: 0.3481 - val_auc: 0.7751 - val_precision: 0.6006 - val_recall: 0.2458 - val_R2: 0.1542 - val_binary_crossentropy: 0.2099 - val_false_positives: 1919.0000 - val_false_negatives: 8856.0000 - val_true_positives: 2886.0000 - val_true_negatives: 146611.0000 - val_precision_over_recall: 0.3683 - val_roc: 0.7751\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 50s 728ms/step - loss: 0.1538 - f1_score: 0.4549 - auc: 0.8849 - precision: 0.7542 - recall: 0.3682 - R2: 0.3194 - binary_crossentropy: 0.1540 - false_positives: 12719.0000 - false_negatives: 66967.0000 - true_positives: 39020.0000 - true_negatives: 1323714.0000 - precision_over_recall: 0.6151 - roc: 0.8849 - val_loss: 0.2095 - val_f1_score: 0.3419 - val_auc: 0.7750 - val_precision: 0.5975 - val_recall: 0.2487 - val_R2: 0.1492 - val_binary_crossentropy: 0.2097 - val_false_positives: 1967.0000 - val_false_negatives: 8822.0000 - val_true_positives: 2920.0000 - val_true_negatives: 146563.0000 - val_precision_over_recall: 0.3638 - val_roc: 0.7750\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 0.1530 - f1_score: 0.4564 - auc: 0.8864 - precision: 0.7578 - recall: 0.3723 - R2: 0.3243 - binary_crossentropy: 0.1530 - false_positives: 12610.0000 - false_negatives: 66532.0000 - true_positives: 39455.0000 - true_negatives: 1323823.0000 - precision_over_recall: 0.6182 - roc: 0.8864 - val_loss: 0.2108 - val_f1_score: 0.3463 - val_auc: 0.7713 - val_precision: 0.5992 - val_recall: 0.2557 - val_R2: 0.1543 - val_binary_crossentropy: 0.2112 - val_false_positives: 2008.0000 - val_false_negatives: 8740.0000 - val_true_positives: 3002.0000 - val_true_negatives: 146522.0000 - val_precision_over_recall: 0.3690 - val_roc: 0.7713\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 58s 856ms/step - loss: 0.1524 - f1_score: 0.4592 - auc: 0.8869 - precision: 0.7555 - recall: 0.3766 - R2: 0.3263 - binary_crossentropy: 0.1525 - false_positives: 12920.0000 - false_negatives: 66073.0000 - true_positives: 39914.0000 - true_negatives: 1323513.0000 - precision_over_recall: 0.6222 - roc: 0.8869 - val_loss: 0.2133 - val_f1_score: 0.3441 - val_auc: 0.7732 - val_precision: 0.5973 - val_recall: 0.2546 - val_R2: 0.1492 - val_binary_crossentropy: 0.2136 - val_false_positives: 2016.0000 - val_false_negatives: 8752.0000 - val_true_positives: 2990.0000 - val_true_negatives: 146514.0000 - val_precision_over_recall: 0.3635 - val_roc: 0.7732\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 51s 751ms/step - loss: 0.1515 - f1_score: 0.4618 - auc: 0.8895 - precision: 0.7590 - recall: 0.3785 - R2: 0.3302 - binary_crossentropy: 0.1515 - false_positives: 12739.0000 - false_negatives: 65867.0000 - true_positives: 40120.0000 - true_negatives: 1323694.0000 - precision_over_recall: 0.6343 - roc: 0.8895 - val_loss: 0.2130 - val_f1_score: 0.3442 - val_auc: 0.7695 - val_precision: 0.5869 - val_recall: 0.2576 - val_R2: 0.1487 - val_binary_crossentropy: 0.2132 - val_false_positives: 2129.0000 - val_false_negatives: 8717.0000 - val_true_positives: 3025.0000 - val_true_negatives: 146401.0000 - val_precision_over_recall: 0.3673 - val_roc: 0.7695\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 49s 728ms/step - loss: 0.1511 - f1_score: 0.4638 - auc: 0.8893 - precision: 0.7600 - recall: 0.3832 - R2: 0.3317 - binary_crossentropy: 0.1511 - false_positives: 12828.0000 - false_negatives: 65375.0000 - true_positives: 40612.0000 - true_negatives: 1323605.0000 - precision_over_recall: 0.6308 - roc: 0.8893 - val_loss: 0.2153 - val_f1_score: 0.3439 - val_auc: 0.7697 - val_precision: 0.5870 - val_recall: 0.2598 - val_R2: 0.1500 - val_binary_crossentropy: 0.2156 - val_false_positives: 2146.0000 - val_false_negatives: 8692.0000 - val_true_positives: 3050.0000 - val_true_negatives: 146384.0000 - val_precision_over_recall: 0.3695 - val_roc: 0.7697\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 50s 733ms/step - loss: 0.1506 - f1_score: 0.4633 - auc: 0.8904 - precision: 0.7624 - recall: 0.3840 - R2: 0.3333 - binary_crossentropy: 0.1505 - false_positives: 12682.0000 - false_negatives: 65285.0000 - true_positives: 40702.0000 - true_negatives: 1323751.0000 - precision_over_recall: 0.6324 - roc: 0.8904 - val_loss: 0.2152 - val_f1_score: 0.3491 - val_auc: 0.7718 - val_precision: 0.5853 - val_recall: 0.2554 - val_R2: 0.1526 - val_binary_crossentropy: 0.2152 - val_false_positives: 2125.0000 - val_false_negatives: 8743.0000 - val_true_positives: 2999.0000 - val_true_negatives: 146405.0000 - val_precision_over_recall: 0.3765 - val_roc: 0.7718\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 50s 734ms/step - loss: 0.1501 - f1_score: 0.4655 - auc: 0.8905 - precision: 0.7646 - recall: 0.3874 - R2: 0.3359 - binary_crossentropy: 0.1502 - false_positives: 12639.0000 - false_negatives: 64930.0000 - true_positives: 41057.0000 - true_negatives: 1323794.0000 - precision_over_recall: 0.6389 - roc: 0.8905 - val_loss: 0.2162 - val_f1_score: 0.3449 - val_auc: 0.7712 - val_precision: 0.5866 - val_recall: 0.2586 - val_R2: 0.1463 - val_binary_crossentropy: 0.2163 - val_false_positives: 2140.0000 - val_false_negatives: 8705.0000 - val_true_positives: 3037.0000 - val_true_negatives: 146390.0000 - val_precision_over_recall: 0.3749 - val_roc: 0.7712\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 50s 736ms/step - loss: 0.1500 - f1_score: 0.4654 - auc: 0.8908 - precision: 0.7615 - recall: 0.3877 - R2: 0.3357 - binary_crossentropy: 0.1502 - false_positives: 12872.0000 - false_negatives: 64891.0000 - true_positives: 41096.0000 - true_negatives: 1323561.0000 - precision_over_recall: 0.6380 - roc: 0.8908 - val_loss: 0.2168 - val_f1_score: 0.3455 - val_auc: 0.7703 - val_precision: 0.5918 - val_recall: 0.2582 - val_R2: 0.1452 - val_binary_crossentropy: 0.2169 - val_false_positives: 2091.0000 - val_false_negatives: 8710.0000 - val_true_positives: 3032.0000 - val_true_negatives: 146439.0000 - val_precision_over_recall: 0.3707 - val_roc: 0.7703\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 50s 740ms/step - loss: 0.1489 - f1_score: 0.4679 - auc: 0.8925 - precision: 0.7648 - recall: 0.3921 - R2: 0.3406 - binary_crossentropy: 0.1490 - false_positives: 12784.0000 - false_negatives: 64426.0000 - true_positives: 41561.0000 - true_negatives: 1323649.0000 - precision_over_recall: 0.6521 - roc: 0.8925 - val_loss: 0.2171 - val_f1_score: 0.3441 - val_auc: 0.7696 - val_precision: 0.5818 - val_recall: 0.2604 - val_R2: 0.1464 - val_binary_crossentropy: 0.2173 - val_false_positives: 2198.0000 - val_false_negatives: 8684.0000 - val_true_positives: 3058.0000 - val_true_negatives: 146332.0000 - val_precision_over_recall: 0.3710 - val_roc: 0.7696\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 52s 769ms/step - loss: 0.1489 - f1_score: 0.4682 - auc: 0.8934 - precision: 0.7653 - recall: 0.3921 - R2: 0.3417 - binary_crossentropy: 0.1489 - false_positives: 12741.0000 - false_negatives: 64432.0000 - true_positives: 41555.0000 - true_negatives: 1323692.0000 - precision_over_recall: 0.6480 - roc: 0.8934 - val_loss: 0.2194 - val_f1_score: 0.3431 - val_auc: 0.7700 - val_precision: 0.5859 - val_recall: 0.2517 - val_R2: 0.1448 - val_binary_crossentropy: 0.2194 - val_false_positives: 2089.0000 - val_false_negatives: 8786.0000 - val_true_positives: 2956.0000 - val_true_negatives: 146441.0000 - val_precision_over_recall: 0.3638 - val_roc: 0.7700\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 54s 799ms/step - loss: 0.1477 - f1_score: 0.4694 - auc: 0.8955 - precision: 0.7643 - recall: 0.3978 - R2: 0.3463 - binary_crossentropy: 0.1477 - false_positives: 12998.0000 - false_negatives: 63827.0000 - true_positives: 42160.0000 - true_negatives: 1323435.0000 - precision_over_recall: 0.6577 - roc: 0.8955 - val_loss: 0.2181 - val_f1_score: 0.3447 - val_auc: 0.7712 - val_precision: 0.5821 - val_recall: 0.2511 - val_R2: 0.1488 - val_binary_crossentropy: 0.2180 - val_false_positives: 2117.0000 - val_false_negatives: 8793.0000 - val_true_positives: 2949.0000 - val_true_negatives: 146413.0000 - val_precision_over_recall: 0.3717 - val_roc: 0.7712\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 52s 768ms/step - loss: 0.1466 - f1_score: 0.4725 - auc: 0.8968 - precision: 0.7697 - recall: 0.3998 - R2: 0.3506 - binary_crossentropy: 0.1465 - false_positives: 12676.0000 - false_negatives: 63616.0000 - true_positives: 42371.0000 - true_negatives: 1323757.0000 - precision_over_recall: 0.6663 - roc: 0.8968 - val_loss: 0.2213 - val_f1_score: 0.3435 - val_auc: 0.7713 - val_precision: 0.5742 - val_recall: 0.2574 - val_R2: 0.1411 - val_binary_crossentropy: 0.2215 - val_false_positives: 2241.0000 - val_false_negatives: 8720.0000 - val_true_positives: 3022.0000 - val_true_negatives: 146289.0000 - val_precision_over_recall: 0.3682 - val_roc: 0.7713\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 51s 751ms/step - loss: 0.1465 - f1_score: 0.4721 - auc: 0.8976 - precision: 0.7689 - recall: 0.4026 - R2: 0.3514 - binary_crossentropy: 0.1462 - false_positives: 12821.0000 - false_negatives: 63319.0000 - true_positives: 42668.0000 - true_negatives: 1323612.0000 - precision_over_recall: 0.6613 - roc: 0.8976 - val_loss: 0.2196 - val_f1_score: 0.3452 - val_auc: 0.7723 - val_precision: 0.5791 - val_recall: 0.2637 - val_R2: 0.1470 - val_binary_crossentropy: 0.2196 - val_false_positives: 2250.0000 - val_false_negatives: 8646.0000 - val_true_positives: 3096.0000 - val_true_negatives: 146280.0000 - val_precision_over_recall: 0.3758 - val_roc: 0.7723\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 0.1456 - f1_score: 0.4739 - auc: 0.8992 - precision: 0.7714 - recall: 0.4050 - R2: 0.3548 - binary_crossentropy: 0.1458 - false_positives: 12725.0000 - false_negatives: 63058.0000 - true_positives: 42929.0000 - true_negatives: 1323708.0000 - precision_over_recall: 0.6690 - roc: 0.8992 - val_loss: 0.2226 - val_f1_score: 0.3444 - val_auc: 0.7680 - val_precision: 0.5737 - val_recall: 0.2609 - val_R2: 0.1422 - val_binary_crossentropy: 0.2232 - val_false_positives: 2276.0000 - val_false_negatives: 8679.0000 - val_true_positives: 3063.0000 - val_true_negatives: 146254.0000 - val_precision_over_recall: 0.3642 - val_roc: 0.7680\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 50s 742ms/step - loss: 0.1452 - f1_score: 0.4764 - auc: 0.8988 - precision: 0.7728 - recall: 0.4081 - R2: 0.3556 - binary_crossentropy: 0.1452 - false_positives: 12714.0000 - false_negatives: 62734.0000 - true_positives: 43253.0000 - true_negatives: 1323719.0000 - precision_over_recall: 0.6734 - roc: 0.8988 - val_loss: 0.2253 - val_f1_score: 0.3447 - val_auc: 0.7666 - val_precision: 0.5705 - val_recall: 0.2656 - val_R2: 0.1365 - val_binary_crossentropy: 0.2255 - val_false_positives: 2348.0000 - val_false_negatives: 8623.0000 - val_true_positives: 3119.0000 - val_true_negatives: 146182.0000 - val_precision_over_recall: 0.3695 - val_roc: 0.7666\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 50s 743ms/step - loss: 0.1444 - f1_score: 0.4767 - auc: 0.9001 - precision: 0.7739 - recall: 0.4101 - R2: 0.3592 - binary_crossentropy: 0.1445 - false_positives: 12702.0000 - false_negatives: 62521.0000 - true_positives: 43466.0000 - true_negatives: 1323731.0000 - precision_over_recall: 0.6760 - roc: 0.9001 - val_loss: 0.2262 - val_f1_score: 0.3452 - val_auc: 0.7683 - val_precision: 0.5681 - val_recall: 0.2643 - val_R2: 0.1402 - val_binary_crossentropy: 0.2266 - val_false_positives: 2359.0000 - val_false_negatives: 8639.0000 - val_true_positives: 3103.0000 - val_true_negatives: 146171.0000 - val_precision_over_recall: 0.3656 - val_roc: 0.7683\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 51s 747ms/step - loss: 0.1437 - f1_score: 0.4781 - auc: 0.9017 - precision: 0.7743 - recall: 0.4147 - R2: 0.3608 - binary_crossentropy: 0.1437 - false_positives: 12812.0000 - false_negatives: 62039.0000 - true_positives: 43948.0000 - true_negatives: 1323621.0000 - precision_over_recall: 0.6808 - roc: 0.9017 - val_loss: 0.2296 - val_f1_score: 0.3424 - val_auc: 0.7674 - val_precision: 0.5594 - val_recall: 0.2631 - val_R2: 0.1355 - val_binary_crossentropy: 0.2298 - val_false_positives: 2433.0000 - val_false_negatives: 8653.0000 - val_true_positives: 3089.0000 - val_true_negatives: 146097.0000 - val_precision_over_recall: 0.3624 - val_roc: 0.7674\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 50s 741ms/step - loss: 0.1441 - f1_score: 0.4786 - auc: 0.9019 - precision: 0.7739 - recall: 0.4123 - R2: 0.3602 - binary_crossentropy: 0.1440 - false_positives: 12765.0000 - false_negatives: 62284.0000 - true_positives: 43703.0000 - true_negatives: 1323668.0000 - precision_over_recall: 0.6806 - roc: 0.9019 - val_loss: 0.2260 - val_f1_score: 0.3348 - val_auc: 0.7649 - val_precision: 0.5573 - val_recall: 0.2556 - val_R2: 0.1304 - val_binary_crossentropy: 0.2264 - val_false_positives: 2384.0000 - val_false_negatives: 8741.0000 - val_true_positives: 3001.0000 - val_true_negatives: 146146.0000 - val_precision_over_recall: 0.3575 - val_roc: 0.7649\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 51s 749ms/step - loss: 0.1448 - f1_score: 0.4766 - auc: 0.9009 - precision: 0.7737 - recall: 0.4078 - R2: 0.3568 - binary_crossentropy: 0.1445 - false_positives: 12642.0000 - false_negatives: 62764.0000 - true_positives: 43223.0000 - true_negatives: 1323791.0000 - precision_over_recall: 0.6748 - roc: 0.9009 - val_loss: 0.2255 - val_f1_score: 0.3432 - val_auc: 0.7651 - val_precision: 0.5656 - val_recall: 0.2602 - val_R2: 0.1393 - val_binary_crossentropy: 0.2257 - val_false_positives: 2346.0000 - val_false_negatives: 8687.0000 - val_true_positives: 3055.0000 - val_true_negatives: 146184.0000 - val_precision_over_recall: 0.3716 - val_roc: 0.7651\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 51s 752ms/step - loss: 0.1436 - f1_score: 0.4784 - auc: 0.9022 - precision: 0.7742 - recall: 0.4148 - R2: 0.3608 - binary_crossentropy: 0.1437 - false_positives: 12823.0000 - false_negatives: 62024.0000 - true_positives: 43963.0000 - true_negatives: 1323610.0000 - precision_over_recall: 0.6806 - roc: 0.9022 - val_loss: 0.2271 - val_f1_score: 0.3376 - val_auc: 0.7647 - val_precision: 0.5579 - val_recall: 0.2592 - val_R2: 0.1308 - val_binary_crossentropy: 0.2269 - val_false_positives: 2412.0000 - val_false_negatives: 8698.0000 - val_true_positives: 3044.0000 - val_true_negatives: 146118.0000 - val_precision_over_recall: 0.3648 - val_roc: 0.7647\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 51s 756ms/step - loss: 0.1433 - f1_score: 0.4787 - auc: 0.9026 - precision: 0.7754 - recall: 0.4157 - R2: 0.3616 - binary_crossentropy: 0.1437 - false_positives: 12761.0000 - false_negatives: 61925.0000 - true_positives: 44062.0000 - true_negatives: 1323672.0000 - precision_over_recall: 0.6862 - roc: 0.9026 - val_loss: 0.2275 - val_f1_score: 0.3365 - val_auc: 0.7630 - val_precision: 0.5531 - val_recall: 0.2587 - val_R2: 0.1321 - val_binary_crossentropy: 0.2276 - val_false_positives: 2455.0000 - val_false_negatives: 8704.0000 - val_true_positives: 3038.0000 - val_true_negatives: 146075.0000 - val_precision_over_recall: 0.3620 - val_roc: 0.7630\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 51s 757ms/step - loss: 0.1425 - f1_score: 0.4796 - auc: 0.9040 - precision: 0.7763 - recall: 0.4170 - R2: 0.3654 - binary_crossentropy: 0.1423 - false_positives: 12734.0000 - false_negatives: 61788.0000 - true_positives: 44199.0000 - true_negatives: 1323699.0000 - precision_over_recall: 0.6858 - roc: 0.9040 - val_loss: 0.2292 - val_f1_score: 0.3360 - val_auc: 0.7630 - val_precision: 0.5532 - val_recall: 0.2576 - val_R2: 0.1286 - val_binary_crossentropy: 0.2296 - val_false_positives: 2443.0000 - val_false_negatives: 8717.0000 - val_true_positives: 3025.0000 - val_true_negatives: 146087.0000 - val_precision_over_recall: 0.3597 - val_roc: 0.7630\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 51s 753ms/step - loss: 0.1415 - f1_score: 0.4821 - auc: 0.9057 - precision: 0.7787 - recall: 0.4244 - R2: 0.3707 - binary_crossentropy: 0.1413 - false_positives: 12783.0000 - false_negatives: 61008.0000 - true_positives: 44979.0000 - true_negatives: 1323650.0000 - precision_over_recall: 0.6936 - roc: 0.9057 - val_loss: 0.2352 - val_f1_score: 0.3318 - val_auc: 0.7597 - val_precision: 0.5472 - val_recall: 0.2610 - val_R2: 0.1202 - val_binary_crossentropy: 0.2354 - val_false_positives: 2536.0000 - val_false_negatives: 8677.0000 - val_true_positives: 3065.0000 - val_true_negatives: 145994.0000 - val_precision_over_recall: 0.3535 - val_roc: 0.7597\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.1425 - f1_score: 0.4812 - auc: 0.9041 - precision: 0.7738 - recall: 0.4216 - R2: 0.3647 - binary_crossentropy: 0.1426 - false_positives: 13064.0000 - false_negatives: 61306.0000 - true_positives: 44681.0000 - true_negatives: 1323369.0000 - precision_over_recall: 0.6906 - roc: 0.9041 - val_loss: 0.2289 - val_f1_score: 0.3346 - val_auc: 0.7634 - val_precision: 0.5547 - val_recall: 0.2538 - val_R2: 0.1284 - val_binary_crossentropy: 0.2291 - val_false_positives: 2392.0000 - val_false_negatives: 8762.0000 - val_true_positives: 2980.0000 - val_true_negatives: 146138.0000 - val_precision_over_recall: 0.3585 - val_roc: 0.7634\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 58s 859ms/step - loss: 0.1423 - f1_score: 0.4816 - auc: 0.9037 - precision: 0.7762 - recall: 0.4206 - R2: 0.3662 - binary_crossentropy: 0.1422 - false_positives: 12849.0000 - false_negatives: 61412.0000 - true_positives: 44575.0000 - true_negatives: 1323584.0000 - precision_over_recall: 0.6902 - roc: 0.9037 - val_loss: 0.2344 - val_f1_score: 0.3346 - val_auc: 0.7622 - val_precision: 0.5498 - val_recall: 0.2546 - val_R2: 0.1200 - val_binary_crossentropy: 0.2343 - val_false_positives: 2448.0000 - val_false_negatives: 8752.0000 - val_true_positives: 2990.0000 - val_true_negatives: 146082.0000 - val_precision_over_recall: 0.3486 - val_roc: 0.7622\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 52s 768ms/step - loss: 0.1412 - f1_score: 0.4828 - auc: 0.9055 - precision: 0.7798 - recall: 0.4249 - R2: 0.3717 - binary_crossentropy: 0.1411 - false_positives: 12715.0000 - false_negatives: 60954.0000 - true_positives: 45033.0000 - true_negatives: 1323718.0000 - precision_over_recall: 0.7007 - roc: 0.9055 - val_loss: 0.2305 - val_f1_score: 0.3412 - val_auc: 0.7619 - val_precision: 0.5526 - val_recall: 0.2641 - val_R2: 0.1256 - val_binary_crossentropy: 0.2309 - val_false_positives: 2511.0000 - val_false_negatives: 8641.0000 - val_true_positives: 3101.0000 - val_true_negatives: 146019.0000 - val_precision_over_recall: 0.3642 - val_roc: 0.7619\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 50s 735ms/step - loss: 0.1409 - f1_score: 0.4835 - auc: 0.9067 - precision: 0.7793 - recall: 0.4257 - R2: 0.3718 - binary_crossentropy: 0.1410 - false_positives: 12780.0000 - false_negatives: 60871.0000 - true_positives: 45116.0000 - true_negatives: 1323653.0000 - precision_over_recall: 0.6991 - roc: 0.9067 - val_loss: 0.2332 - val_f1_score: 0.3386 - val_auc: 0.7615 - val_precision: 0.5452 - val_recall: 0.2640 - val_R2: 0.1249 - val_binary_crossentropy: 0.2326 - val_false_positives: 2586.0000 - val_false_negatives: 8642.0000 - val_true_positives: 3100.0000 - val_true_negatives: 145944.0000 - val_precision_over_recall: 0.3600 - val_roc: 0.7615\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 50s 737ms/step - loss: 0.1402 - f1_score: 0.4849 - auc: 0.9078 - precision: 0.7812 - recall: 0.4314 - R2: 0.3756 - binary_crossentropy: 0.1405 - false_positives: 12807.0000 - false_negatives: 60264.0000 - true_positives: 45723.0000 - true_negatives: 1323626.0000 - precision_over_recall: 0.7061 - roc: 0.9078 - val_loss: 0.2294 - val_f1_score: 0.3378 - val_auc: 0.7636 - val_precision: 0.5424 - val_recall: 0.2635 - val_R2: 0.1242 - val_binary_crossentropy: 0.2295 - val_false_positives: 2610.0000 - val_false_negatives: 8648.0000 - val_true_positives: 3094.0000 - val_true_negatives: 145920.0000 - val_precision_over_recall: 0.3608 - val_roc: 0.7636\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 50s 738ms/step - loss: 0.1407 - f1_score: 0.4843 - auc: 0.9071 - precision: 0.7784 - recall: 0.4277 - R2: 0.3730 - binary_crossentropy: 0.1405 - false_positives: 12905.0000 - false_negatives: 60661.0000 - true_positives: 45326.0000 - true_negatives: 1323528.0000 - precision_over_recall: 0.7016 - roc: 0.9071 - val_loss: 0.2356 - val_f1_score: 0.3380 - val_auc: 0.7619 - val_precision: 0.5366 - val_recall: 0.2632 - val_R2: 0.1170 - val_binary_crossentropy: 0.2355 - val_false_positives: 2669.0000 - val_false_negatives: 8651.0000 - val_true_positives: 3091.0000 - val_true_negatives: 145861.0000 - val_precision_over_recall: 0.3543 - val_roc: 0.7619\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 0.1388 - f1_score: 0.4881 - auc: 0.9089 - precision: 0.7816 - recall: 0.4358 - R2: 0.3803 - binary_crossentropy: 0.1389 - false_positives: 12905.0000 - false_negatives: 59800.0000 - true_positives: 46187.0000 - true_negatives: 1323528.0000 - precision_over_recall: 0.7120 - roc: 0.9089 - val_loss: 0.2348 - val_f1_score: 0.3409 - val_auc: 0.7595 - val_precision: 0.5502 - val_recall: 0.2575 - val_R2: 0.1219 - val_binary_crossentropy: 0.2349 - val_false_positives: 2472.0000 - val_false_negatives: 8718.0000 - val_true_positives: 3024.0000 - val_true_negatives: 146058.0000 - val_precision_over_recall: 0.3563 - val_roc: 0.7595\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 0.1383 - f1_score: 0.4879 - auc: 0.9108 - precision: 0.7830 - recall: 0.4392 - R2: 0.3835 - binary_crossentropy: 0.1385 - false_positives: 12899.0000 - false_negatives: 59436.0000 - true_positives: 46551.0000 - true_negatives: 1323534.0000 - precision_over_recall: 0.7175 - roc: 0.9108 - val_loss: 0.2358 - val_f1_score: 0.3384 - val_auc: 0.7609 - val_precision: 0.5507 - val_recall: 0.2555 - val_R2: 0.1220 - val_binary_crossentropy: 0.2358 - val_false_positives: 2448.0000 - val_false_negatives: 8742.0000 - val_true_positives: 3000.0000 - val_true_negatives: 146082.0000 - val_precision_over_recall: 0.3546 - val_roc: 0.7609\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 57s 845ms/step - loss: 0.1390 - f1_score: 0.4874 - auc: 0.9091 - precision: 0.7818 - recall: 0.4347 - R2: 0.3803 - binary_crossentropy: 0.1390 - false_positives: 12858.0000 - false_negatives: 59913.0000 - true_positives: 46074.0000 - true_negatives: 1323575.0000 - precision_over_recall: 0.7114 - roc: 0.9091 - val_loss: 0.2369 - val_f1_score: 0.3379 - val_auc: 0.7574 - val_precision: 0.5439 - val_recall: 0.2577 - val_R2: 0.1229 - val_binary_crossentropy: 0.2369 - val_false_positives: 2538.0000 - val_false_negatives: 8716.0000 - val_true_positives: 3026.0000 - val_true_negatives: 145992.0000 - val_precision_over_recall: 0.3525 - val_roc: 0.7574\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 53s 772ms/step - loss: 0.1387 - f1_score: 0.4876 - auc: 0.9099 - precision: 0.7835 - recall: 0.4372 - R2: 0.3814 - binary_crossentropy: 0.1387 - false_positives: 12806.0000 - false_negatives: 59646.0000 - true_positives: 46341.0000 - true_negatives: 1323627.0000 - precision_over_recall: 0.7115 - roc: 0.9099 - val_loss: 0.2382 - val_f1_score: 0.3387 - val_auc: 0.7616 - val_precision: 0.5555 - val_recall: 0.2580 - val_R2: 0.1205 - val_binary_crossentropy: 0.2380 - val_false_positives: 2425.0000 - val_false_negatives: 8712.0000 - val_true_positives: 3030.0000 - val_true_negatives: 146105.0000 - val_precision_over_recall: 0.3513 - val_roc: 0.7616\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 49s 727ms/step - loss: 0.1382 - f1_score: 0.4885 - auc: 0.9107 - precision: 0.7850 - recall: 0.4379 - R2: 0.3839 - binary_crossentropy: 0.1383 - false_positives: 12712.0000 - false_negatives: 59579.0000 - true_positives: 46408.0000 - true_negatives: 1323721.0000 - precision_over_recall: 0.7184 - roc: 0.9107 - val_loss: 0.2382 - val_f1_score: 0.3347 - val_auc: 0.7630 - val_precision: 0.5452 - val_recall: 0.2554 - val_R2: 0.1151 - val_binary_crossentropy: 0.2381 - val_false_positives: 2502.0000 - val_false_negatives: 8743.0000 - val_true_positives: 2999.0000 - val_true_negatives: 146028.0000 - val_precision_over_recall: 0.3481 - val_roc: 0.7630\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 50s 729ms/step - loss: 0.1381 - f1_score: 0.4888 - auc: 0.9101 - precision: 0.7843 - recall: 0.4390 - R2: 0.3832 - binary_crossentropy: 0.1383 - false_positives: 12799.0000 - false_negatives: 59460.0000 - true_positives: 46527.0000 - true_negatives: 1323634.0000 - precision_over_recall: 0.7174 - roc: 0.9101 - val_loss: 0.2384 - val_f1_score: 0.3376 - val_auc: 0.7609 - val_precision: 0.5444 - val_recall: 0.2635 - val_R2: 0.1183 - val_binary_crossentropy: 0.2383 - val_false_positives: 2589.0000 - val_false_negatives: 8648.0000 - val_true_positives: 3094.0000 - val_true_negatives: 145941.0000 - val_precision_over_recall: 0.3602 - val_roc: 0.7609\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 50s 742ms/step - loss: 0.1376 - f1_score: 0.4906 - auc: 0.9119 - precision: 0.7827 - recall: 0.4441 - R2: 0.3862 - binary_crossentropy: 0.1379 - false_positives: 13063.0000 - false_negatives: 58922.0000 - true_positives: 47065.0000 - true_negatives: 1323370.0000 - precision_over_recall: 0.7206 - roc: 0.9119 - val_loss: 0.2371 - val_f1_score: 0.3387 - val_auc: 0.7603 - val_precision: 0.5400 - val_recall: 0.2671 - val_R2: 0.1160 - val_binary_crossentropy: 0.2370 - val_false_positives: 2671.0000 - val_false_negatives: 8606.0000 - val_true_positives: 3136.0000 - val_true_negatives: 145859.0000 - val_precision_over_recall: 0.3503 - val_roc: 0.7603\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1366 - f1_score: 0.4916 - auc: 0.9125 - precision: 0.7880 - recall: 0.4461 - R2: 0.3891 - binary_crossentropy: 0.1364 - false_positives: 12722.0000 - false_negatives: 58707.0000 - true_positives: 47280.0000 - true_negatives: 1323711.0000 - precision_over_recall: 0.7318 - roc: 0.9125 - val_loss: 0.2457 - val_f1_score: 0.3359 - val_auc: 0.7574 - val_precision: 0.5419 - val_recall: 0.2597 - val_R2: 0.1143 - val_binary_crossentropy: 0.2455 - val_false_positives: 2578.0000 - val_false_negatives: 8693.0000 - val_true_positives: 3049.0000 - val_true_negatives: 145952.0000 - val_precision_over_recall: 0.3615 - val_roc: 0.7574\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 52s 759ms/step - loss: 0.1358 - f1_score: 0.4932 - auc: 0.9134 - precision: 0.7878 - recall: 0.4500 - R2: 0.3930 - binary_crossentropy: 0.1355 - false_positives: 12845.0000 - false_negatives: 58296.0000 - true_positives: 47691.0000 - true_negatives: 1323588.0000 - precision_over_recall: 0.7347 - roc: 0.9134 - val_loss: 0.2456 - val_f1_score: 0.3389 - val_auc: 0.7579 - val_precision: 0.5471 - val_recall: 0.2606 - val_R2: 0.1174 - val_binary_crossentropy: 0.2451 - val_false_positives: 2533.0000 - val_false_negatives: 8682.0000 - val_true_positives: 3060.0000 - val_true_negatives: 145997.0000 - val_precision_over_recall: 0.3537 - val_roc: 0.7579\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 52s 759ms/step - loss: 0.1358 - f1_score: 0.4941 - auc: 0.9130 - precision: 0.7896 - recall: 0.4512 - R2: 0.3940 - binary_crossentropy: 0.1360 - false_positives: 12746.0000 - false_negatives: 58162.0000 - true_positives: 47825.0000 - true_negatives: 1323687.0000 - precision_over_recall: 0.7365 - roc: 0.9130 - val_loss: 0.2400 - val_f1_score: 0.3367 - val_auc: 0.7589 - val_precision: 0.5414 - val_recall: 0.2590 - val_R2: 0.1153 - val_binary_crossentropy: 0.2396 - val_false_positives: 2576.0000 - val_false_negatives: 8701.0000 - val_true_positives: 3041.0000 - val_true_negatives: 145954.0000 - val_precision_over_recall: 0.3571 - val_roc: 0.7589\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1352 - f1_score: 0.4949 - auc: 0.9145 - precision: 0.7888 - recall: 0.4537 - R2: 0.3972 - binary_crossentropy: 0.1355 - false_positives: 12874.0000 - false_negatives: 57903.0000 - true_positives: 48084.0000 - true_negatives: 1323559.0000 - precision_over_recall: 0.7388 - roc: 0.9145 - val_loss: 0.2437 - val_f1_score: 0.3365 - val_auc: 0.7559 - val_precision: 0.5416 - val_recall: 0.2569 - val_R2: 0.1108 - val_binary_crossentropy: 0.2431 - val_false_positives: 2553.0000 - val_false_negatives: 8726.0000 - val_true_positives: 3016.0000 - val_true_negatives: 145977.0000 - val_precision_over_recall: 0.3546 - val_roc: 0.7559\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1347 - f1_score: 0.4963 - auc: 0.9152 - precision: 0.7915 - recall: 0.4534 - R2: 0.3984 - binary_crossentropy: 0.1348 - false_positives: 12654.0000 - false_negatives: 57936.0000 - true_positives: 48051.0000 - true_negatives: 1323779.0000 - precision_over_recall: 0.7425 - roc: 0.9152 - val_loss: 0.2452 - val_f1_score: 0.3362 - val_auc: 0.7604 - val_precision: 0.5390 - val_recall: 0.2626 - val_R2: 0.1061 - val_binary_crossentropy: 0.2447 - val_false_positives: 2637.0000 - val_false_negatives: 8659.0000 - val_true_positives: 3083.0000 - val_true_negatives: 145893.0000 - val_precision_over_recall: 0.3512 - val_roc: 0.7604\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1337 - f1_score: 0.4962 - auc: 0.9165 - precision: 0.7912 - recall: 0.4583 - R2: 0.4019 - binary_crossentropy: 0.1334 - false_positives: 12820.0000 - false_negatives: 57418.0000 - true_positives: 48569.0000 - true_negatives: 1323613.0000 - precision_over_recall: 0.7460 - roc: 0.9165 - val_loss: 0.2459 - val_f1_score: 0.3349 - val_auc: 0.7555 - val_precision: 0.5375 - val_recall: 0.2611 - val_R2: 0.1090 - val_binary_crossentropy: 0.2452 - val_false_positives: 2638.0000 - val_false_negatives: 8676.0000 - val_true_positives: 3066.0000 - val_true_negatives: 145892.0000 - val_precision_over_recall: 0.3516 - val_roc: 0.7555\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 51s 757ms/step - loss: 0.1330 - f1_score: 0.4993 - auc: 0.9171 - precision: 0.7940 - recall: 0.4618 - R2: 0.4059 - binary_crossentropy: 0.1328 - false_positives: 12696.0000 - false_negatives: 57043.0000 - true_positives: 48944.0000 - true_negatives: 1323737.0000 - precision_over_recall: 0.7522 - roc: 0.9171 - val_loss: 0.2488 - val_f1_score: 0.3373 - val_auc: 0.7568 - val_precision: 0.5419 - val_recall: 0.2643 - val_R2: 0.1097 - val_binary_crossentropy: 0.2485 - val_false_positives: 2623.0000 - val_false_negatives: 8639.0000 - val_true_positives: 3103.0000 - val_true_negatives: 145907.0000 - val_precision_over_recall: 0.3570 - val_roc: 0.7568\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1333 - f1_score: 0.4976 - auc: 0.9169 - precision: 0.7923 - recall: 0.4605 - R2: 0.4031 - binary_crossentropy: 0.1335 - false_positives: 12794.0000 - false_negatives: 57181.0000 - true_positives: 48806.0000 - true_negatives: 1323639.0000 - precision_over_recall: 0.7501 - roc: 0.9169 - val_loss: 0.2491 - val_f1_score: 0.3391 - val_auc: 0.7549 - val_precision: 0.5367 - val_recall: 0.2662 - val_R2: 0.1093 - val_binary_crossentropy: 0.2488 - val_false_positives: 2698.0000 - val_false_negatives: 8616.0000 - val_true_positives: 3126.0000 - val_true_negatives: 145832.0000 - val_precision_over_recall: 0.3512 - val_roc: 0.7549\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1327 - f1_score: 0.4989 - auc: 0.9183 - precision: 0.7949 - recall: 0.4635 - R2: 0.4046 - binary_crossentropy: 0.1328 - false_positives: 12674.0000 - false_negatives: 56857.0000 - true_positives: 49130.0000 - true_negatives: 1323759.0000 - precision_over_recall: 0.7526 - roc: 0.9183 - val_loss: 0.2494 - val_f1_score: 0.3364 - val_auc: 0.7552 - val_precision: 0.5227 - val_recall: 0.2698 - val_R2: 0.0995 - val_binary_crossentropy: 0.2490 - val_false_positives: 2893.0000 - val_false_negatives: 8574.0000 - val_true_positives: 3168.0000 - val_true_negatives: 145637.0000 - val_precision_over_recall: 0.3494 - val_roc: 0.7552\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1326 - f1_score: 0.4990 - auc: 0.9180 - precision: 0.7922 - recall: 0.4660 - R2: 0.4070 - binary_crossentropy: 0.1326 - false_positives: 12954.0000 - false_negatives: 56595.0000 - true_positives: 49392.0000 - true_negatives: 1323479.0000 - precision_over_recall: 0.7550 - roc: 0.9180 - val_loss: 0.2477 - val_f1_score: 0.3296 - val_auc: 0.7570 - val_precision: 0.5321 - val_recall: 0.2634 - val_R2: 0.1019 - val_binary_crossentropy: 0.2474 - val_false_positives: 2720.0000 - val_false_negatives: 8649.0000 - val_true_positives: 3093.0000 - val_true_negatives: 145810.0000 - val_precision_over_recall: 0.3443 - val_roc: 0.7570\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1313 - f1_score: 0.5022 - auc: 0.9192 - precision: 0.7987 - recall: 0.4674 - R2: 0.4114 - binary_crossentropy: 0.1312 - false_positives: 12488.0000 - false_negatives: 56444.0000 - true_positives: 49543.0000 - true_negatives: 1323945.0000 - precision_over_recall: 0.7646 - roc: 0.9192 - val_loss: 0.2529 - val_f1_score: 0.3313 - val_auc: 0.7526 - val_precision: 0.5268 - val_recall: 0.2750 - val_R2: 0.1016 - val_binary_crossentropy: 0.2523 - val_false_positives: 2901.0000 - val_false_negatives: 8513.0000 - val_true_positives: 3229.0000 - val_true_negatives: 145629.0000 - val_precision_over_recall: 0.3495 - val_roc: 0.7526\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1314 - f1_score: 0.5006 - auc: 0.9193 - precision: 0.7945 - recall: 0.4699 - R2: 0.4117 - binary_crossentropy: 0.1315 - false_positives: 12880.0000 - false_negatives: 56184.0000 - true_positives: 49803.0000 - true_negatives: 1323553.0000 - precision_over_recall: 0.7608 - roc: 0.9193 - val_loss: 0.2547 - val_f1_score: 0.3342 - val_auc: 0.7567 - val_precision: 0.5264 - val_recall: 0.2755 - val_R2: 0.1018 - val_binary_crossentropy: 0.2541 - val_false_positives: 2910.0000 - val_false_negatives: 8507.0000 - val_true_positives: 3235.0000 - val_true_negatives: 145620.0000 - val_precision_over_recall: 0.3509 - val_roc: 0.7567\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1307 - f1_score: 0.5026 - auc: 0.9205 - precision: 0.7993 - recall: 0.4730 - R2: 0.4143 - binary_crossentropy: 0.1311 - false_positives: 12589.0000 - false_negatives: 55860.0000 - true_positives: 50127.0000 - true_negatives: 1323844.0000 - precision_over_recall: 0.7696 - roc: 0.9205 - val_loss: 0.2527 - val_f1_score: 0.3359 - val_auc: 0.7555 - val_precision: 0.5376 - val_recall: 0.2677 - val_R2: 0.1072 - val_binary_crossentropy: 0.2519 - val_false_positives: 2703.0000 - val_false_negatives: 8599.0000 - val_true_positives: 3143.0000 - val_true_negatives: 145827.0000 - val_precision_over_recall: 0.3528 - val_roc: 0.7555\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1300 - f1_score: 0.5042 - auc: 0.9211 - precision: 0.8001 - recall: 0.4751 - R2: 0.4177 - binary_crossentropy: 0.1300 - false_positives: 12580.0000 - false_negatives: 55629.0000 - true_positives: 50358.0000 - true_negatives: 1323853.0000 - precision_over_recall: 0.7744 - roc: 0.9211 - val_loss: 0.2552 - val_f1_score: 0.3360 - val_auc: 0.7498 - val_precision: 0.5258 - val_recall: 0.2705 - val_R2: 0.1015 - val_binary_crossentropy: 0.2548 - val_false_positives: 2864.0000 - val_false_negatives: 8566.0000 - val_true_positives: 3176.0000 - val_true_negatives: 145666.0000 - val_precision_over_recall: 0.3550 - val_roc: 0.7498\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1304 - f1_score: 0.5037 - auc: 0.9206 - precision: 0.7958 - recall: 0.4749 - R2: 0.4168 - binary_crossentropy: 0.1307 - false_positives: 12919.0000 - false_negatives: 55649.0000 - true_positives: 50338.0000 - true_negatives: 1323514.0000 - precision_over_recall: 0.7705 - roc: 0.9206 - val_loss: 0.2479 - val_f1_score: 0.3379 - val_auc: 0.7559 - val_precision: 0.5361 - val_recall: 0.2659 - val_R2: 0.1012 - val_binary_crossentropy: 0.2474 - val_false_positives: 2702.0000 - val_false_negatives: 8620.0000 - val_true_positives: 3122.0000 - val_true_negatives: 145828.0000 - val_precision_over_recall: 0.3443 - val_roc: 0.7559\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1305 - f1_score: 0.5027 - auc: 0.9203 - precision: 0.7983 - recall: 0.4725 - R2: 0.4155 - binary_crossentropy: 0.1304 - false_positives: 12654.0000 - false_negatives: 55912.0000 - true_positives: 50075.0000 - true_negatives: 1323779.0000 - precision_over_recall: 0.7700 - roc: 0.9203 - val_loss: 0.2557 - val_f1_score: 0.3371 - val_auc: 0.7516 - val_precision: 0.5313 - val_recall: 0.2656 - val_R2: 0.0996 - val_binary_crossentropy: 0.2551 - val_false_positives: 2752.0000 - val_false_negatives: 8623.0000 - val_true_positives: 3119.0000 - val_true_negatives: 145778.0000 - val_precision_over_recall: 0.3443 - val_roc: 0.7516\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1293 - f1_score: 0.5049 - auc: 0.9221 - precision: 0.7989 - recall: 0.4783 - R2: 0.4201 - binary_crossentropy: 0.1294 - false_positives: 12758.0000 - false_negatives: 55297.0000 - true_positives: 50690.0000 - true_negatives: 1323675.0000 - precision_over_recall: 0.7769 - roc: 0.9221 - val_loss: 0.2510 - val_f1_score: 0.3308 - val_auc: 0.7553 - val_precision: 0.5264 - val_recall: 0.2562 - val_R2: 0.0956 - val_binary_crossentropy: 0.2504 - val_false_positives: 2706.0000 - val_false_negatives: 8734.0000 - val_true_positives: 3008.0000 - val_true_negatives: 145824.0000 - val_precision_over_recall: 0.3382 - val_roc: 0.7553\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 51s 757ms/step - loss: 0.1288 - f1_score: 0.5061 - auc: 0.9234 - precision: 0.8007 - recall: 0.4806 - R2: 0.4230 - binary_crossentropy: 0.1287 - false_positives: 12674.0000 - false_negatives: 55054.0000 - true_positives: 50933.0000 - true_negatives: 1323759.0000 - precision_over_recall: 0.7789 - roc: 0.9234 - val_loss: 0.2573 - val_f1_score: 0.3291 - val_auc: 0.7513 - val_precision: 0.5163 - val_recall: 0.2690 - val_R2: 0.0959 - val_binary_crossentropy: 0.2565 - val_false_positives: 2960.0000 - val_false_negatives: 8583.0000 - val_true_positives: 3159.0000 - val_true_negatives: 145570.0000 - val_precision_over_recall: 0.3506 - val_roc: 0.7513\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1279 - f1_score: 0.5086 - auc: 0.9242 - precision: 0.8028 - recall: 0.4863 - R2: 0.4257 - binary_crossentropy: 0.1280 - false_positives: 12661.0000 - false_negatives: 54444.0000 - true_positives: 51543.0000 - true_negatives: 1323772.0000 - precision_over_recall: 0.7869 - roc: 0.9242 - val_loss: 0.2648 - val_f1_score: 0.3333 - val_auc: 0.7474 - val_precision: 0.5197 - val_recall: 0.2713 - val_R2: 0.0902 - val_binary_crossentropy: 0.2643 - val_false_positives: 2945.0000 - val_false_negatives: 8556.0000 - val_true_positives: 3186.0000 - val_true_negatives: 145585.0000 - val_precision_over_recall: 0.3458 - val_roc: 0.7474\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 51s 757ms/step - loss: 0.1280 - f1_score: 0.5081 - auc: 0.9246 - precision: 0.8005 - recall: 0.4852 - R2: 0.4281 - binary_crossentropy: 0.1282 - false_positives: 12818.0000 - false_negatives: 54560.0000 - true_positives: 51427.0000 - true_negatives: 1323615.0000 - precision_over_recall: 0.7852 - roc: 0.9246 - val_loss: 0.2585 - val_f1_score: 0.3330 - val_auc: 0.7496 - val_precision: 0.5246 - val_recall: 0.2594 - val_R2: 0.0926 - val_binary_crossentropy: 0.2584 - val_false_positives: 2760.0000 - val_false_negatives: 8696.0000 - val_true_positives: 3046.0000 - val_true_negatives: 145770.0000 - val_precision_over_recall: 0.3430 - val_roc: 0.7496\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1275 - f1_score: 0.5087 - auc: 0.9243 - precision: 0.8010 - recall: 0.4892 - R2: 0.4296 - binary_crossentropy: 0.1275 - false_positives: 12883.0000 - false_negatives: 54138.0000 - true_positives: 51849.0000 - true_negatives: 1323550.0000 - precision_over_recall: 0.7893 - roc: 0.9243 - val_loss: 0.2606 - val_f1_score: 0.3290 - val_auc: 0.7489 - val_precision: 0.5172 - val_recall: 0.2607 - val_R2: 0.0847 - val_binary_crossentropy: 0.2605 - val_false_positives: 2857.0000 - val_false_negatives: 8681.0000 - val_true_positives: 3061.0000 - val_true_negatives: 145673.0000 - val_precision_over_recall: 0.3315 - val_roc: 0.7489\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1271 - f1_score: 0.5102 - auc: 0.9255 - precision: 0.8045 - recall: 0.4891 - R2: 0.4307 - binary_crossentropy: 0.1272 - false_positives: 12598.0000 - false_negatives: 54144.0000 - true_positives: 51843.0000 - true_negatives: 1323835.0000 - precision_over_recall: 0.7928 - roc: 0.9255 - val_loss: 0.2696 - val_f1_score: 0.3320 - val_auc: 0.7469 - val_precision: 0.5139 - val_recall: 0.2749 - val_R2: 0.0856 - val_binary_crossentropy: 0.2686 - val_false_positives: 3053.0000 - val_false_negatives: 8514.0000 - val_true_positives: 3228.0000 - val_true_negatives: 145477.0000 - val_precision_over_recall: 0.3373 - val_roc: 0.7469\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 51s 757ms/step - loss: 0.1265 - f1_score: 0.5108 - auc: 0.9265 - precision: 0.8036 - recall: 0.4916 - R2: 0.4325 - binary_crossentropy: 0.1265 - false_positives: 12736.0000 - false_negatives: 53884.0000 - true_positives: 52103.0000 - true_negatives: 1323697.0000 - precision_over_recall: 0.7918 - roc: 0.9265 - val_loss: 0.2659 - val_f1_score: 0.3282 - val_auc: 0.7450 - val_precision: 0.5070 - val_recall: 0.2672 - val_R2: 0.0837 - val_binary_crossentropy: 0.2652 - val_false_positives: 3051.0000 - val_false_negatives: 8604.0000 - val_true_positives: 3138.0000 - val_true_negatives: 145479.0000 - val_precision_over_recall: 0.3431 - val_roc: 0.7450\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 52s 759ms/step - loss: 0.1257 - f1_score: 0.5118 - auc: 0.9266 - precision: 0.8062 - recall: 0.4953 - R2: 0.4356 - binary_crossentropy: 0.1256 - false_positives: 12620.0000 - false_negatives: 53487.0000 - true_positives: 52500.0000 - true_negatives: 1323813.0000 - precision_over_recall: 0.8012 - roc: 0.9266 - val_loss: 0.2640 - val_f1_score: 0.3300 - val_auc: 0.7467 - val_precision: 0.5014 - val_recall: 0.2670 - val_R2: 0.0799 - val_binary_crossentropy: 0.2638 - val_false_positives: 3118.0000 - val_false_negatives: 8607.0000 - val_true_positives: 3135.0000 - val_true_negatives: 145412.0000 - val_precision_over_recall: 0.3447 - val_roc: 0.7467\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 51s 758ms/step - loss: 0.1261 - f1_score: 0.5116 - auc: 0.9275 - precision: 0.8045 - recall: 0.4939 - R2: 0.4330 - binary_crossentropy: 0.1261 - false_positives: 12724.0000 - false_negatives: 53635.0000 - true_positives: 52352.0000 - true_negatives: 1323709.0000 - precision_over_recall: 0.7964 - roc: 0.9275 - val_loss: 0.2666 - val_f1_score: 0.3290 - val_auc: 0.7459 - val_precision: 0.5122 - val_recall: 0.2654 - val_R2: 0.0800 - val_binary_crossentropy: 0.2663 - val_false_positives: 2968.0000 - val_false_negatives: 8626.0000 - val_true_positives: 3116.0000 - val_true_negatives: 145562.0000 - val_precision_over_recall: 0.3368 - val_roc: 0.7459\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1258 - f1_score: 0.5117 - auc: 0.9270 - precision: 0.8024 - recall: 0.4948 - R2: 0.4344 - binary_crossentropy: 0.1258 - false_positives: 12912.0000 - false_negatives: 53544.0000 - true_positives: 52443.0000 - true_negatives: 1323521.0000 - precision_over_recall: 0.7943 - roc: 0.9270 - val_loss: 0.2660 - val_f1_score: 0.3281 - val_auc: 0.7486 - val_precision: 0.5099 - val_recall: 0.2701 - val_R2: 0.0884 - val_binary_crossentropy: 0.2656 - val_false_positives: 3048.0000 - val_false_negatives: 8571.0000 - val_true_positives: 3171.0000 - val_true_negatives: 145482.0000 - val_precision_over_recall: 0.3371 - val_roc: 0.7486\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.1252 - f1_score: 0.5130 - auc: 0.9280 - precision: 0.8081 - recall: 0.4994 - R2: 0.4379 - binary_crossentropy: 0.1254 - false_positives: 12566.0000 - false_negatives: 53055.0000 - true_positives: 52932.0000 - true_negatives: 1323867.0000 - precision_over_recall: 0.8065 - roc: 0.9280 - val_loss: 0.2591 - val_f1_score: 0.3291 - val_auc: 0.7476 - val_precision: 0.5095 - val_recall: 0.2602 - val_R2: 0.0880 - val_binary_crossentropy: 0.2592 - val_false_positives: 2941.0000 - val_false_negatives: 8687.0000 - val_true_positives: 3055.0000 - val_true_negatives: 145589.0000 - val_precision_over_recall: 0.3337 - val_roc: 0.7476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), workers=2, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# plot the history\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 7s 36ms/step - loss: 0.2123 - f1_score: 0.3131 - auc: 0.7546 - precision: 0.6299 - recall: 0.1654 - R2: 0.1207 - binary_crossentropy: 0.2123 - false_positives: 1141.0000 - false_negatives: 9800.0000 - true_positives: 1942.0000 - true_negatives: 147389.0000 - precision_over_recall: 0.3105 - roc: 0.7546\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy, precision, recall  \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall,_  = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
